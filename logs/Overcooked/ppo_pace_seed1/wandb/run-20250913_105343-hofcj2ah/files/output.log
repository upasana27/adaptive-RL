Updates 0, num timesteps 72000, FPS 797
 Last 1800 training episodes: mean/median reward -7.3161/-7.3175, min/max reward -7.3600/-7.2750
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 2.125
 Evaluation using 45 episodes: {'reward': -7.300000000000001, 'reward_per_opponent': array([-7.4, -7.3, -7.4, -7.1, -7.2, -7.2, -7.5, -7.2, -7.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 2.2222222222222223}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 1, num timesteps 144000, FPS 771
 Last 1800 training episodes: mean/median reward -7.3192/-7.3250, min/max reward -7.3550/-7.2650
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 2.3
 Evaluation using 45 episodes: {'reward': -7.222222222222222, 'reward_per_opponent': array([-7.1, -7.3, -7.3, -7.2, -7.3, -7.4, -7.1, -7.3, -7. ]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 1.8888888888888888}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 2, num timesteps 216000, FPS 771
 Last 1800 training episodes: mean/median reward -7.3217/-7.3275, min/max reward -7.3800/-7.2700
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 2.341666666666667
Updates 3, num timesteps 288000, FPS 817
 Last 1800 training episodes: mean/median reward -7.3164/-7.3175, min/max reward -7.3500/-7.2800
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 2.2194444444444446
 Evaluation using 45 episodes: {'reward': -7.366666666666666, 'reward_per_opponent': array([-7.3, -7.5, -7.4, -7.3, -7.3, -7.4, -7.3, -7.5, -7.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 1.3333333333333333}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 4, num timesteps 360000, FPS 698
 Last 1800 training episodes: mean/median reward -7.3125/-7.3100, min/max reward -7.4050/-7.2500
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 2.2583333333333333
 Evaluation using 45 episodes: {'reward': -7.333333333333333, 'reward_per_opponent': array([-7.2, -7.4, -7.3, -7.3, -7.4, -7.3, -7.3, -7.3, -7.5]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 2.2222222222222223}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 5, num timesteps 432000, FPS 777
 Last 1800 training episodes: mean/median reward -7.3294/-7.3275, min/max reward -7.3750/-7.2600
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 2.325
 Evaluation using 45 episodes: {'reward': -7.277777777777778, 'reward_per_opponent': array([-7.4, -7.3, -7.5, -7.1, -7.2, -7. , -7.3, -7.3, -7.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 2.2222222222222223}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 6, num timesteps 504000, FPS 762
 Last 1800 training episodes: mean/median reward -7.3161/-7.3125, min/max reward -7.3650/-7.2750
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 2.15
Updates 7, num timesteps 576000, FPS 802
 Last 1800 training episodes: mean/median reward -7.3117/-7.3100, min/max reward -7.3600/-7.2750
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 2.2083333333333335
 Evaluation using 45 episodes: {'reward': -7.344444444444445, 'reward_per_opponent': array([-7.5, -7.3, -7.4, -7.3, -7.3, -7.2, -7.5, -7.2, -7.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 2.7777777777777777}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 8, num timesteps 648000, FPS 695
 Last 1800 training episodes: mean/median reward -7.3197/-7.3175, min/max reward -7.3700/-7.2850
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 2.1833333333333336
 Evaluation using 45 episodes: {'reward': -7.333333333333333, 'reward_per_opponent': array([-7.3, -7.4, -7.2, -7.4, -7.3, -7.4, -7.3, -7.4, -7.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 2.2222222222222223}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 9, num timesteps 720000, FPS 774
 Last 1800 training episodes: mean/median reward -7.3203/-7.3125, min/max reward -7.3650/-7.2550
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 2.2277777777777774
Updates 10, num timesteps 792000, FPS 827
 Last 1800 training episodes: mean/median reward -7.3364/-7.3375, min/max reward -7.3750/-7.2950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 2.3472222222222223
 Evaluation using 45 episodes: {'reward': -7.355555555555556, 'reward_per_opponent': array([-7.4, -7.4, -7. , -7.2, -7.4, -7.5, -7.5, -7.5, -7.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 2.888888888888889}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 11, num timesteps 864000, FPS 777
 Last 1800 training episodes: mean/median reward -7.3267/-7.3325, min/max reward -7.3650/-7.2800
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 2.297222222222222
 Evaluation using 45 episodes: {'reward': -7.333333333333333, 'reward_per_opponent': array([-7.5, -7.5, -7.5, -7.3, -7. , -7.2, -7.4, -7.2, -7.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 1.8888888888888888}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 12, num timesteps 936000, FPS 779
 Last 1800 training episodes: mean/median reward -7.3175/-7.3150, min/max reward -7.3700/-7.2700
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 2.2527777777777778
 Evaluation using 45 episodes: {'reward': -7.311111111111111, 'reward_per_opponent': array([-7.5, -7.3, -7.1, -7.2, -7.4, -7.3, -7.3, -7.4, -7.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 2.2222222222222223}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 13, num timesteps 1008000, FPS 780
 Last 1800 training episodes: mean/median reward -7.3314/-7.3275, min/max reward -7.4050/-7.2900
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 2.1944444444444446
Updates 14, num timesteps 1080000, FPS 817
 Last 1800 training episodes: mean/median reward -7.3128/-7.3125, min/max reward -7.3850/-7.2600
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 2.2527777777777778
 Evaluation using 45 episodes: {'reward': -7.199999999999999, 'reward_per_opponent': array([-7.2, -7.3, -7.2, -7.2, -7.1, -6.9, -7.4, -7.3, -7.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 1.4444444444444444}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 15, num timesteps 1152000, FPS 757
 Last 1800 training episodes: mean/median reward -7.2556/-7.2575, min/max reward -7.3000/-7.1800
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 1.577777777777778
 Evaluation using 45 episodes: {'reward': -7.199999999999999, 'reward_per_opponent': array([-6.9, -7.2, -7.4, -7.2, -7. , -7.4, -7.1, -7.3, -7.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.7777777777777778}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 16, num timesteps 1224000, FPS 764
 Last 1800 training episodes: mean/median reward -7.1922/-7.1975, min/max reward -7.2350/-7.1350
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 1.0166666666666668
Updates 17, num timesteps 1296000, FPS 807
 Last 1800 training episodes: mean/median reward -7.1258/-7.1225, min/max reward -7.1750/-7.0750
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.6694444444444445
 Evaluation using 45 episodes: {'reward': -6.98888888888889, 'reward_per_opponent': array([-6.8, -7. , -7. , -6.9, -6.9, -7. , -7.2, -7.1, -7. ]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.3333333333333333}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 18, num timesteps 1368000, FPS 769
 Last 1800 training episodes: mean/median reward -7.0503/-7.0500, min/max reward -7.1250/-6.9750
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.32222222222222224
 Evaluation using 45 episodes: {'reward': -6.955555555555555, 'reward_per_opponent': array([-7.1, -7.3, -6.9, -7. , -6.8, -6.8, -6.9, -6.9, -6.9]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 19, num timesteps 1440000, FPS 762
 Last 1800 training episodes: mean/median reward -6.9681/-6.9700, min/max reward -7.0350/-6.9250
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.22499999999999998
 Evaluation using 45 episodes: {'reward': -6.877777777777777, 'reward_per_opponent': array([-6.8, -6.9, -6.9, -6.8, -7.1, -6.7, -6.8, -7. , -6.9]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 20, num timesteps 1512000, FPS 758
 Last 1800 training episodes: mean/median reward -6.9192/-6.9100, min/max reward -7.0200/-6.8600
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.1
Updates 21, num timesteps 1584000, FPS 740
 Last 1800 training episodes: mean/median reward -6.8772/-6.8725, min/max reward -6.9450/-6.8200
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.05000000000000001
 Evaluation using 45 episodes: {'reward': -6.855555555555556, 'reward_per_opponent': array([-6.9, -6.7, -6.8, -7. , -6.8, -6.9, -7. , -7. , -6.6]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 22, num timesteps 1656000, FPS 772
 Last 1800 training episodes: mean/median reward -6.8122/-6.8225, min/max reward -6.8800/-6.7150
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.044444444444444446
 Evaluation using 45 episodes: {'reward': -6.877777777777778, 'reward_per_opponent': array([-6.8, -7. , -6.8, -6.9, -6.9, -7. , -6.9, -6.9, -6.7]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 23, num timesteps 1728000, FPS 762
 Last 1800 training episodes: mean/median reward -6.8281/-6.8250, min/max reward -6.9150/-6.7600
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.052777777777777785
 Evaluation using 45 episodes: {'reward': -6.755555555555556, 'reward_per_opponent': array([-6.7, -6.8, -6.8, -6.7, -6.8, -6.8, -6.8, -6.8, -6.6]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 24, num timesteps 1800000, FPS 762
 Last 1800 training episodes: mean/median reward -6.8069/-6.8100, min/max reward -6.8850/-6.7400
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.025
Updates 25, num timesteps 1872000, FPS 808
 Last 1800 training episodes: mean/median reward -6.7864/-6.7900, min/max reward -6.8350/-6.7450
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.013888888888888888
 Evaluation using 45 episodes: {'reward': -6.866666666666666, 'reward_per_opponent': array([-6.8, -6.8, -6.8, -7. , -6.9, -6.9, -7. , -6.8, -6.8]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 26, num timesteps 1944000, FPS 754
 Last 1800 training episodes: mean/median reward -6.7850/-6.7800, min/max reward -6.8650/-6.7000
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.019444444444444445
 Evaluation using 45 episodes: {'reward': -6.844444444444444, 'reward_per_opponent': array([-7.1, -6.8, -6.9, -6.9, -6.8, -6.8, -6.7, -6.8, -6.8]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.1111111111111111}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 27, num timesteps 2016000, FPS 769
 Last 1800 training episodes: mean/median reward -6.8000/-6.7950, min/max reward -6.9000/-6.7150
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.011111111111111112
Updates 28, num timesteps 2088000, FPS 804
 Last 1800 training episodes: mean/median reward -6.7950/-6.7950, min/max reward -6.8750/-6.7200
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.008333333333333335
 Evaluation using 45 episodes: {'reward': -6.866666666666666, 'reward_per_opponent': array([-6.6, -6.8, -6.9, -6.9, -6.8, -6.7, -7. , -6.9, -7.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 29, num timesteps 2160000, FPS 759
 Last 1800 training episodes: mean/median reward -6.7769/-6.7750, min/max reward -6.8500/-6.7200
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.005555555555555556
 Evaluation using 45 episodes: {'reward': -6.877777777777777, 'reward_per_opponent': array([-6.8, -6.8, -6.9, -7.1, -6.8, -6.8, -7. , -6.7, -7. ]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 30, num timesteps 2232000, FPS 771
 Last 1800 training episodes: mean/median reward -6.7650/-6.7575, min/max reward -6.8500/-6.7150
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.011111111111111112
 Evaluation using 45 episodes: {'reward': -6.9, 'reward_per_opponent': array([-7. , -7. , -7. , -6.8, -7. , -6.8, -6.8, -6.8, -6.9]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 31, num timesteps 2304000, FPS 739
 Last 1800 training episodes: mean/median reward -6.7950/-6.8025, min/max reward -6.8850/-6.6400
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 32, num timesteps 2376000, FPS 809
 Last 1800 training episodes: mean/median reward -6.8031/-6.8100, min/max reward -6.8450/-6.7050
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.002777777777777778
 Evaluation using 45 episodes: {'reward': -6.911111111111111, 'reward_per_opponent': array([-7. , -7. , -7. , -7.1, -6.8, -6.8, -6.9, -6.7, -6.9]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 33, num timesteps 2448000, FPS 788
 Last 1800 training episodes: mean/median reward -6.8197/-6.8375, min/max reward -6.8800/-6.7400
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.005555555555555556
 Evaluation using 45 episodes: {'reward': -6.777777777777778, 'reward_per_opponent': array([-6.7, -6.6, -6.9, -6.8, -6.8, -6.7, -6.8, -7. , -6.7]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 34, num timesteps 2520000, FPS 763
 Last 1800 training episodes: mean/median reward -6.8075/-6.8050, min/max reward -6.8750/-6.7350
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.013888888888888888
Updates 35, num timesteps 2592000, FPS 808
 Last 1800 training episodes: mean/median reward -6.8094/-6.8100, min/max reward -6.8800/-6.7250
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.011111111111111112
 Evaluation using 45 episodes: {'reward': -6.833333333333333, 'reward_per_opponent': array([-6.8, -6.9, -7. , -6.9, -6.9, -6.8, -6.7, -6.8, -6.7]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 36, num timesteps 2664000, FPS 774
 Last 1800 training episodes: mean/median reward -6.8158/-6.8150, min/max reward -6.8850/-6.7400
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.019444444444444445
 Evaluation using 45 episodes: {'reward': -6.811111111111112, 'reward_per_opponent': array([-6.9, -6.9, -6.9, -6.7, -6.8, -6.7, -6.8, -6.7, -6.9]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 37, num timesteps 2736000, FPS 770
 Last 1800 training episodes: mean/median reward -6.8036/-6.8050, min/max reward -6.8500/-6.7050
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.005555555555555556
 Evaluation using 45 episodes: {'reward': -6.788888888888889, 'reward_per_opponent': array([-6.8, -6.7, -6.7, -6.9, -6.8, -7. , -6.8, -6.8, -6.6]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 38, num timesteps 2808000, FPS 761
 Last 1800 training episodes: mean/median reward -6.8217/-6.8250, min/max reward -6.8950/-6.7600
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.008333333333333335
Updates 39, num timesteps 2880000, FPS 798
 Last 1800 training episodes: mean/median reward -6.8283/-6.8275, min/max reward -6.9000/-6.7000
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.016666666666666666
 Evaluation using 45 episodes: {'reward': -6.800000000000001, 'reward_per_opponent': array([-6.7, -6.8, -6.9, -6.6, -7.1, -6.9, -6.7, -6.5, -7. ]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 40, num timesteps 2952000, FPS 766
 Last 1800 training episodes: mean/median reward -6.8531/-6.8475, min/max reward -6.9800/-6.7300
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.013888888888888888
 Evaluation using 45 episodes: {'reward': -6.844444444444445, 'reward_per_opponent': array([-6.8, -7. , -6.7, -7. , -6.8, -6.8, -6.8, -6.6, -7.1]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 41, num timesteps 3024000, FPS 753
 Last 1800 training episodes: mean/median reward -6.8214/-6.8225, min/max reward -6.9050/-6.6900
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.002777777777777778
Updates 42, num timesteps 3096000, FPS 787
 Last 1800 training episodes: mean/median reward -6.8222/-6.8275, min/max reward -6.9250/-6.7300
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.011111111111111112
 Evaluation using 45 episodes: {'reward': -6.777777777777778, 'reward_per_opponent': array([-6.8, -6.9, -6.9, -6.4, -6.6, -6.8, -6.9, -6.9, -6.8]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 43, num timesteps 3168000, FPS 745
 Last 1800 training episodes: mean/median reward -6.8081/-6.8275, min/max reward -6.8700/-6.7350
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.005555555555555556
 Evaluation using 45 episodes: {'reward': -6.822222222222221, 'reward_per_opponent': array([-6.7, -7. , -7.1, -6.9, -6.8, -6.8, -6.7, -6.6, -6.8]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 44, num timesteps 3240000, FPS 758
 Last 1800 training episodes: mean/median reward -6.7750/-6.7750, min/max reward -6.8750/-6.6450
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.833333333333333, 'reward_per_opponent': array([-6.8, -6.8, -6.7, -6.8, -6.7, -7.1, -6.9, -6.9, -6.8]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 45, num timesteps 3312000, FPS 759
 Last 1800 training episodes: mean/median reward -6.7581/-6.7625, min/max reward -6.8800/-6.6450
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.013888888888888888
Updates 46, num timesteps 3384000, FPS 800
 Last 1800 training episodes: mean/median reward -6.7667/-6.7625, min/max reward -6.8700/-6.6700
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.02222222222222222
 Evaluation using 45 episodes: {'reward': -6.7333333333333325, 'reward_per_opponent': array([-6.7, -6.7, -6.5, -6.9, -6.8, -6.8, -6.8, -6.6, -6.8]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 47, num timesteps 3456000, FPS 767
 Last 1800 training episodes: mean/median reward -6.7639/-6.7725, min/max reward -6.8500/-6.6900
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.01666666666666667
 Evaluation using 45 episodes: {'reward': -6.733333333333334, 'reward_per_opponent': array([-6.8, -6.7, -6.8, -6.8, -6.7, -6.6, -6.8, -6.7, -6.7]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.1111111111111111}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 48, num timesteps 3528000, FPS 758
 Last 1800 training episodes: mean/median reward -6.7444/-6.7500, min/max reward -6.8350/-6.6450
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.011111111111111112
 Evaluation using 45 episodes: {'reward': -6.755555555555556, 'reward_per_opponent': array([-6.8, -6.9, -6.8, -6.9, -6.5, -6.8, -6.7, -6.7, -6.7]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 49, num timesteps 3600000, FPS 773
 Last 1800 training episodes: mean/median reward -6.7208/-6.7250, min/max reward -6.8150/-6.6450
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.005555555555555556
Updates 50, num timesteps 3672000, FPS 809
 Last 1800 training episodes: mean/median reward -6.7158/-6.7150, min/max reward -6.8250/-6.6400
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.005555555555555556
 Evaluation using 45 episodes: {'reward': -6.788888888888889, 'reward_per_opponent': array([-6.8, -6.6, -6.8, -6.9, -6.5, -6.7, -7. , -6.9, -6.9]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 51, num timesteps 3744000, FPS 760
 Last 1800 training episodes: mean/median reward -6.7014/-6.7100, min/max reward -6.7800/-6.5850
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.008333333333333335
 Evaluation using 45 episodes: {'reward': -6.6, 'reward_per_opponent': array([-6.5, -6.5, -6.3, -6.9, -6.7, -6.5, -6.6, -6.8, -6.6]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 52, num timesteps 3816000, FPS 768
 Last 1800 training episodes: mean/median reward -6.6967/-6.6950, min/max reward -6.7850/-6.5900
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.002777777777777778
Updates 53, num timesteps 3888000, FPS 808
 Last 1800 training episodes: mean/median reward -6.6706/-6.6675, min/max reward -6.7700/-6.5950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.008333333333333335
 Evaluation using 45 episodes: {'reward': -6.811111111111111, 'reward_per_opponent': array([-6.8, -6.9, -6.7, -6.9, -6.8, -6.8, -6.8, -6.8, -6.8]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 54, num timesteps 3960000, FPS 765
 Last 1800 training episodes: mean/median reward -6.6844/-6.6800, min/max reward -6.7900/-6.5950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.01666666666666667
 Evaluation using 45 episodes: {'reward': -6.633333333333333, 'reward_per_opponent': array([-6.6, -6.6, -6.5, -6.8, -6.7, -6.5, -6.6, -6.8, -6.6]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 55, num timesteps 4032000, FPS 760
 Last 1800 training episodes: mean/median reward -6.6936/-6.7025, min/max reward -6.7450/-6.5900
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.011111111111111112
 Evaluation using 45 episodes: {'reward': -6.7666666666666675, 'reward_per_opponent': array([-6.6, -7.1, -6.7, -6.9, -6.5, -6.9, -6.8, -6.7, -6.7]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 56, num timesteps 4104000, FPS 766
 Last 1800 training episodes: mean/median reward -6.6769/-6.6800, min/max reward -6.7550/-6.5700
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.030555555555555558
Updates 57, num timesteps 4176000, FPS 797
 Last 1800 training episodes: mean/median reward -6.6731/-6.6775, min/max reward -6.7250/-6.5950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.013888888888888888
 Evaluation using 45 episodes: {'reward': -6.711111111111111, 'reward_per_opponent': array([-6.5, -6.9, -6.6, -6.7, -6.8, -6.6, -6.8, -6.6, -6.9]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 58, num timesteps 4248000, FPS 762
 Last 1800 training episodes: mean/median reward -6.6858/-6.6950, min/max reward -6.7350/-6.6100
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.005555555555555556
 Evaluation using 45 episodes: {'reward': -6.666666666666667, 'reward_per_opponent': array([-7. , -6.5, -6.4, -6.6, -6.6, -6.7, -6.9, -6.6, -6.7]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 59, num timesteps 4320000, FPS 756
 Last 1800 training episodes: mean/median reward -6.6822/-6.6875, min/max reward -6.7600/-6.6150
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.025000000000000005
Updates 60, num timesteps 4392000, FPS 805
 Last 1800 training episodes: mean/median reward -6.6717/-6.6750, min/max reward -6.7450/-6.5850
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.011111111111111112
 Evaluation using 45 episodes: {'reward': -6.688888888888889, 'reward_per_opponent': array([-6.4, -6.5, -6.9, -6.8, -6.7, -6.8, -6.8, -6.5, -6.8]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 61, num timesteps 4464000, FPS 762
 Last 1800 training episodes: mean/median reward -6.6803/-6.6875, min/max reward -6.7300/-6.5850
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.013888888888888888
 Evaluation using 45 episodes: {'reward': -6.7444444444444445, 'reward_per_opponent': array([-6.6, -6.7, -6.7, -6.8, -6.7, -7. , -6.9, -6.7, -6.6]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 62, num timesteps 4536000, FPS 771
 Last 1800 training episodes: mean/median reward -6.6692/-6.6725, min/max reward -6.7300/-6.5950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.030555555555555558
 Evaluation using 45 episodes: {'reward': -6.688888888888889, 'reward_per_opponent': array([-6.7, -6.7, -6.5, -6.7, -6.5, -6.8, -6.8, -6.9, -6.6]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.1111111111111111}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 63, num timesteps 4608000, FPS 773
 Last 1800 training episodes: mean/median reward -6.6361/-6.6350, min/max reward -6.6950/-6.5650
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.030555555555555558
Updates 64, num timesteps 4680000, FPS 797
 Last 1800 training episodes: mean/median reward -6.6503/-6.6525, min/max reward -6.7100/-6.5900
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.03333333333333333
 Evaluation using 45 episodes: {'reward': -6.666666666666667, 'reward_per_opponent': array([-6.6, -6.7, -6.6, -6.5, -6.8, -6.7, -6.8, -6.7, -6.6]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.1111111111111111}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 65, num timesteps 4752000, FPS 762
 Last 1800 training episodes: mean/median reward -6.6581/-6.6500, min/max reward -6.7600/-6.5800
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.052777777777777785
 Evaluation using 45 episodes: {'reward': -6.677777777777777, 'reward_per_opponent': array([-6.6, -6.5, -6.6, -6.7, -6.9, -6.7, -6.6, -6.7, -6.8]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 66, num timesteps 4824000, FPS 760
 Last 1800 training episodes: mean/median reward -6.6256/-6.6300, min/max reward -6.6850/-6.5600
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.05555555555555555
Updates 67, num timesteps 4896000, FPS 804
 Last 1800 training episodes: mean/median reward -6.6006/-6.6100, min/max reward -6.6400/-6.5350
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0638888888888889
 Evaluation using 45 episodes: {'reward': -6.744444444444444, 'reward_per_opponent': array([-6.6, -6.7, -6.7, -6.7, -6.8, -6.6, -6.8, -6.9, -6.9]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 68, num timesteps 4968000, FPS 769
 Last 1800 training episodes: mean/median reward -6.5772/-6.5850, min/max reward -6.6650/-6.4750
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.03333333333333334
 Evaluation using 45 episodes: {'reward': -6.677777777777778, 'reward_per_opponent': array([-6.5, -6.9, -6.6, -6.5, -6.8, -6.6, -6.8, -6.7, -6.7]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.1111111111111111}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 69, num timesteps 5040000, FPS 758
 Last 1800 training episodes: mean/median reward -6.5994/-6.6000, min/max reward -6.6600/-6.5100
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.030555555555555558
Model saved.
 Evaluation using 45 episodes: {'reward': -6.711111111111112, 'reward_per_opponent': array([-6.9, -6.8, -6.7, -6.8, -6.6, -6.5, -6.5, -6.9, -6.7]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 70, num timesteps 5112000, FPS 763
 Last 1800 training episodes: mean/median reward -6.5686/-6.5725, min/max reward -6.6150/-6.4950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.05555555555555555
Updates 71, num timesteps 5184000, FPS 813
 Last 1800 training episodes: mean/median reward -6.5281/-6.5325, min/max reward -6.5750/-6.4500
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.05555555555555555
 Evaluation using 45 episodes: {'reward': -6.644444444444445, 'reward_per_opponent': array([-6.2, -6.6, -6.7, -6.6, -7.1, -6.5, -6.7, -6.8, -6.6]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.2222222222222222}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 72, num timesteps 5256000, FPS 759
 Last 1800 training episodes: mean/median reward -6.5375/-6.5375, min/max reward -6.6000/-6.4400
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.04722222222222223
 Evaluation using 45 episodes: {'reward': -6.611111111111112, 'reward_per_opponent': array([-6.5, -6.4, -6.6, -6.6, -6.8, -6.8, -6.7, -6.4, -6.7]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 73, num timesteps 5328000, FPS 756
 Last 1800 training episodes: mean/median reward -6.5147/-6.5150, min/max reward -6.6050/-6.4250
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.024999999999999998
 Evaluation using 45 episodes: {'reward': -6.522222222222222, 'reward_per_opponent': array([-6.2, -6.4, -6.7, -6.7, -6.4, -6.8, -6.7, -6.2, -6.6]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 74, num timesteps 5400000, FPS 769
 Last 1800 training episodes: mean/median reward -6.4806/-6.4825, min/max reward -6.6050/-6.3950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.052777777777777785
Updates 75, num timesteps 5472000, FPS 816
 Last 1800 training episodes: mean/median reward -6.4631/-6.4725, min/max reward -6.5400/-6.3850
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.05555555555555555
 Evaluation using 45 episodes: {'reward': -6.544444444444445, 'reward_per_opponent': array([-6.4, -6.5, -6.3, -6.5, -6.7, -6.4, -6.7, -6.6, -6.8]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 76, num timesteps 5544000, FPS 770
 Last 1800 training episodes: mean/median reward -6.4531/-6.4550, min/max reward -6.5150/-6.3550
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.025
 Evaluation using 45 episodes: {'reward': -6.477777777777778, 'reward_per_opponent': array([-6.4, -6.4, -6.6, -6.2, -6.7, -6.5, -6.6, -6.4, -6.5]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 77, num timesteps 5616000, FPS 766
 Last 1800 training episodes: mean/median reward -6.4094/-6.4000, min/max reward -6.5000/-6.3050
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.047222222222222235
Updates 78, num timesteps 5688000, FPS 805
 Last 1800 training episodes: mean/median reward -6.3817/-6.3800, min/max reward -6.5350/-6.2150
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.03055555555555555
 Evaluation using 45 episodes: {'reward': -6.4444444444444455, 'reward_per_opponent': array([-6.5, -6.3, -6.5, -6.5, -6.4, -6.3, -6.5, -6.4, -6.6]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.2222222222222222}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 79, num timesteps 5760000, FPS 770
 Last 1800 training episodes: mean/median reward -6.3969/-6.4025, min/max reward -6.4950/-6.2350
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.052777777777777785
 Evaluation using 45 episodes: {'reward': -6.466666666666666, 'reward_per_opponent': array([-6.4, -6.6, -6.1, -6.8, -6.5, -6.4, -6.4, -6.6, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 80, num timesteps 5832000, FPS 764
 Last 1800 training episodes: mean/median reward -6.3867/-6.3725, min/max reward -6.5100/-6.2700
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.04722222222222222
 Evaluation using 45 episodes: {'reward': -6.377777777777777, 'reward_per_opponent': array([-6.3, -6.3, -6.3, -6.4, -6.5, -6.3, -6.4, -6.4, -6.5]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.1111111111111111}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 81, num timesteps 5904000, FPS 769
 Last 1800 training episodes: mean/median reward -6.3522/-6.3650, min/max reward -6.4700/-6.1900
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.05555555555555555
Updates 82, num timesteps 5976000, FPS 810
 Last 1800 training episodes: mean/median reward -6.3578/-6.3475, min/max reward -6.4700/-6.2600
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.04166666666666668
 Evaluation using 45 episodes: {'reward': -6.455555555555555, 'reward_per_opponent': array([-6.2, -6.8, -6.4, -6.3, -6.8, -6.3, -6.5, -6.5, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 83, num timesteps 6048000, FPS 771
 Last 1800 training episodes: mean/median reward -6.3514/-6.3750, min/max reward -6.4600/-6.1350
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.036111111111111115
 Evaluation using 45 episodes: {'reward': -6.477777777777778, 'reward_per_opponent': array([-6.4, -6.6, -6.6, -6.7, -6.3, -6.3, -6.6, -6.5, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 84, num timesteps 6120000, FPS 772
 Last 1800 training episodes: mean/median reward -6.3269/-6.3175, min/max reward -6.4450/-6.1850
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.05
Updates 85, num timesteps 6192000, FPS 812
 Last 1800 training episodes: mean/median reward -6.3000/-6.3025, min/max reward -6.4100/-6.1900
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.030555555555555558
 Evaluation using 45 episodes: {'reward': -6.444444444444445, 'reward_per_opponent': array([-6.3, -6.4, -6.6, -6.6, -6.4, -6.3, -6.6, -6.6, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.1111111111111111}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 86, num timesteps 6264000, FPS 774
 Last 1800 training episodes: mean/median reward -6.2958/-6.3025, min/max reward -6.4150/-6.1700
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.03611111111111112
 Evaluation using 45 episodes: {'reward': -6.466666666666667, 'reward_per_opponent': array([-6.3, -6.5, -6.3, -6.4, -6.7, -6.4, -6.5, -6.6, -6.5]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 87, num timesteps 6336000, FPS 773
 Last 1800 training episodes: mean/median reward -6.2717/-6.2725, min/max reward -6.3750/-6.1700
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.030555555555555558
 Evaluation using 45 episodes: {'reward': -6.7, 'reward_per_opponent': array([-6.5, -6.8, -6.8, -6.7, -6.7, -6.9, -6.6, -6.6, -6.7]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.2222222222222222}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 88, num timesteps 6408000, FPS 776
 Last 1800 training episodes: mean/median reward -6.2933/-6.2800, min/max reward -6.4100/-6.1900
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.025
Updates 89, num timesteps 6480000, FPS 821
 Last 1800 training episodes: mean/median reward -6.2550/-6.2750, min/max reward -6.3750/-6.1300
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.025
 Evaluation using 45 episodes: {'reward': -6.522222222222222, 'reward_per_opponent': array([-6.5, -6.6, -6.4, -6.4, -6.6, -6.6, -6.6, -6.6, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 90, num timesteps 6552000, FPS 781
 Last 1800 training episodes: mean/median reward -6.2244/-6.2175, min/max reward -6.3200/-6.0950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.030555555555555558
 Evaluation using 45 episodes: {'reward': -6.366666666666666, 'reward_per_opponent': array([-6.6, -6.5, -6.2, -6.2, -6.5, -6.5, -6.1, -6.3, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.1111111111111111}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 91, num timesteps 6624000, FPS 769
 Last 1800 training episodes: mean/median reward -6.1914/-6.1925, min/max reward -6.3150/-5.9950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.02222222222222222
Updates 92, num timesteps 6696000, FPS 815
 Last 1800 training episodes: mean/median reward -6.1722/-6.1875, min/max reward -6.3250/-6.0300
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.03888888888888889
 Evaluation using 45 episodes: {'reward': -6.433333333333334, 'reward_per_opponent': array([-6.5, -6.4, -6.3, -6.5, -6.2, -6.7, -6.5, -6.3, -6.5]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 93, num timesteps 6768000, FPS 765
 Last 1800 training episodes: mean/median reward -6.1292/-6.1350, min/max reward -6.3300/-5.9550
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.03888888888888889
 Evaluation using 45 episodes: {'reward': -6.333333333333333, 'reward_per_opponent': array([-6.2, -6.4, -6.2, -6.3, -6.4, -6.5, -6.2, -6.4, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.1111111111111111}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 94, num timesteps 6840000, FPS 760
 Last 1800 training episodes: mean/median reward -6.0964/-6.1150, min/max reward -6.2850/-5.8800
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.04722222222222223
 Evaluation using 45 episodes: {'reward': -6.477777777777778, 'reward_per_opponent': array([-6.4, -6.6, -6.3, -6.4, -6.6, -6.5, -6.3, -6.5, -6.7]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.1111111111111111}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 95, num timesteps 6912000, FPS 761
 Last 1800 training episodes: mean/median reward -6.0908/-6.0950, min/max reward -6.2950/-5.9050
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.03333333333333334
Updates 96, num timesteps 6984000, FPS 802
 Last 1800 training episodes: mean/median reward -6.0278/-6.0425, min/max reward -6.2250/-5.8300
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.025
 Evaluation using 45 episodes: {'reward': -6.422222222222222, 'reward_per_opponent': array([-6.6, -6.5, -6.4, -6.2, -6.3, -6.6, -6.3, -6.4, -6.5]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.2222222222222222}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 97, num timesteps 7056000, FPS 757
 Last 1800 training episodes: mean/median reward -6.0186/-6.0100, min/max reward -6.3000/-5.7750
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.027777777777777783
 Evaluation using 45 episodes: {'reward': -6.344444444444445, 'reward_per_opponent': array([-6.3, -6.3, -6.3, -6.2, -6.6, -6.6, -6.3, -6.3, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 98, num timesteps 7128000, FPS 759
 Last 1800 training episodes: mean/median reward -6.0011/-6.0200, min/max reward -6.2500/-5.7050
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.036111111111111115
 Evaluation using 45 episodes: {'reward': -6.4222222222222225, 'reward_per_opponent': array([-6.2, -6.3, -6.5, -6.2, -6.6, -6. , -6.7, -6.7, -6.6]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.1111111111111111}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 99, num timesteps 7200000, FPS 754
 Last 1800 training episodes: mean/median reward -5.9761/-5.9950, min/max reward -6.3050/-5.6650
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.013888888888888888
Updates 100, num timesteps 7272000, FPS 803
 Last 1800 training episodes: mean/median reward -5.9514/-5.9900, min/max reward -6.2150/-5.6550
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.02222222222222222
 Evaluation using 45 episodes: {'reward': -6.366666666666667, 'reward_per_opponent': array([-6.2, -6.4, -6.1, -6.2, -6.4, -6.4, -6.6, -6.4, -6.6]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 101, num timesteps 7344000, FPS 764
 Last 1800 training episodes: mean/median reward -5.9617/-5.9850, min/max reward -6.2650/-5.6050
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.052777777777777785
 Evaluation using 45 episodes: {'reward': -6.311111111111112, 'reward_per_opponent': array([-6.4, -6.3, -6.5, -6.3, -6.4, -6.2, -6.2, -6.3, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.1111111111111111}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 102, num timesteps 7416000, FPS 760
 Last 1800 training episodes: mean/median reward -5.8972/-5.9025, min/max reward -6.2700/-5.5650
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.022222222222222223
Updates 103, num timesteps 7488000, FPS 799
 Last 1800 training episodes: mean/median reward -5.8558/-5.8675, min/max reward -6.2000/-5.5250
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.030555555555555558
 Evaluation using 45 episodes: {'reward': -6.3, 'reward_per_opponent': array([-6.2, -6. , -6.5, -6.4, -6. , -6.1, -6.3, -6.4, -6.8]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.1111111111111111}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 104, num timesteps 7560000, FPS 757
 Last 1800 training episodes: mean/median reward -5.8053/-5.8150, min/max reward -6.2500/-5.3300
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.030555555555555558
 Evaluation using 45 episodes: {'reward': -6.222222222222223, 'reward_per_opponent': array([-6. , -6.3, -6.3, -6.2, -6.3, -6.3, -6.2, -6.3, -6.1]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 105, num timesteps 7632000, FPS 723
 Last 1800 training episodes: mean/median reward -5.7575/-5.7625, min/max reward -6.1800/-5.3250
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.027777777777777776
 Evaluation using 45 episodes: {'reward': -6.266666666666667, 'reward_per_opponent': array([-6.1, -6.3, -6.2, -6.4, -6.5, -6.4, -6.2, -6.4, -5.9]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 106, num timesteps 7704000, FPS 771
 Last 1800 training episodes: mean/median reward -5.7547/-5.8150, min/max reward -6.1200/-5.3600
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.025
Updates 107, num timesteps 7776000, FPS 744
 Last 1800 training episodes: mean/median reward -5.6936/-5.7050, min/max reward -6.1150/-5.2450
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.019444444444444445
 Evaluation using 45 episodes: {'reward': -6.277777777777778, 'reward_per_opponent': array([-6.1, -6.4, -6.2, -6.3, -6.3, -6.2, -6. , -6.5, -6.5]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 108, num timesteps 7848000, FPS 776
 Last 1800 training episodes: mean/median reward -5.6367/-5.6625, min/max reward -6.1400/-5.1100
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.03888888888888889
 Evaluation using 45 episodes: {'reward': -6.211111111111111, 'reward_per_opponent': array([-6.2, -6.2, -6. , -6.1, -6.1, -6.4, -6.3, -6.3, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 109, num timesteps 7920000, FPS 753
 Last 1800 training episodes: mean/median reward -5.5842/-5.6050, min/max reward -6.1350/-5.0300
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.025
Updates 110, num timesteps 7992000, FPS 810
 Last 1800 training episodes: mean/median reward -5.5136/-5.5575, min/max reward -6.1250/-4.9000
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.027777777777777776
 Evaluation using 45 episodes: {'reward': -6.355555555555556, 'reward_per_opponent': array([-6.3, -6.3, -6.3, -6.2, -6.4, -6.5, -6.4, -6.4, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 111, num timesteps 8064000, FPS 771
 Last 1800 training episodes: mean/median reward -5.4617/-5.4675, min/max reward -6.0350/-4.8850
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.01666666666666667
 Evaluation using 45 episodes: {'reward': -6.444444444444445, 'reward_per_opponent': array([-6.5, -6.4, -6.6, -6.3, -6.4, -6.4, -6.5, -6.3, -6.6]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 112, num timesteps 8136000, FPS 760
 Last 1800 training episodes: mean/median reward -5.4439/-5.4650, min/max reward -6.0100/-4.8850
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.016666666666666666
 Evaluation using 45 episodes: {'reward': -6.266666666666666, 'reward_per_opponent': array([-6.4, -6.2, -6.1, -6.6, -6. , -6.1, -6.2, -6.5, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 113, num timesteps 8208000, FPS 778
 Last 1800 training episodes: mean/median reward -5.4142/-5.3850, min/max reward -6.0700/-4.8900
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.005555555555555556
Updates 114, num timesteps 8280000, FPS 813
 Last 1800 training episodes: mean/median reward -5.3647/-5.3575, min/max reward -6.0300/-4.7800
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.01666666666666667
 Evaluation using 45 episodes: {'reward': -6.4222222222222225, 'reward_per_opponent': array([-6.2, -6.5, -6.5, -6.4, -6.4, -6.7, -6.5, -6. , -6.6]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 115, num timesteps 8352000, FPS 774
 Last 1800 training episodes: mean/median reward -5.3628/-5.3525, min/max reward -6.0800/-4.6950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.008333333333333335
 Evaluation using 45 episodes: {'reward': -6.555555555555555, 'reward_per_opponent': array([-6.7, -6.5, -6.4, -6.6, -6.6, -6.5, -6.5, -6.6, -6.6]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 116, num timesteps 8424000, FPS 773
 Last 1800 training episodes: mean/median reward -5.3067/-5.2250, min/max reward -6.0950/-4.7350
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.019444444444444445
Updates 117, num timesteps 8496000, FPS 818
 Last 1800 training episodes: mean/median reward -5.2225/-5.1750, min/max reward -5.9800/-4.6000
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.01666666666666667
 Evaluation using 45 episodes: {'reward': -6.466666666666667, 'reward_per_opponent': array([-6.4, -6.5, -6.7, -6.2, -6.5, -6.5, -6.4, -6.5, -6.5]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 118, num timesteps 8568000, FPS 777
 Last 1800 training episodes: mean/median reward -5.1125/-5.0675, min/max reward -5.9200/-4.5050
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.366666666666667, 'reward_per_opponent': array([-6.7, -6.4, -6.7, -6.1, -6.1, -6.5, -6.4, -6.3, -6.1]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 119, num timesteps 8640000, FPS 771
 Last 1800 training episodes: mean/median reward -5.0819/-4.9875, min/max reward -5.9800/-4.3750
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.036111111111111115
 Evaluation using 45 episodes: {'reward': -6.477777777777778, 'reward_per_opponent': array([-6.4, -6.4, -6.5, -6.7, -6.5, -6.4, -6.3, -6.6, -6.5]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 120, num timesteps 8712000, FPS 768
 Last 1800 training episodes: mean/median reward -5.0944/-5.0075, min/max reward -5.8200/-4.4800
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.025
Updates 121, num timesteps 8784000, FPS 807
 Last 1800 training episodes: mean/median reward -5.0217/-4.9475, min/max reward -5.8550/-4.3950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.008333333333333335
 Evaluation using 45 episodes: {'reward': -6.355555555555555, 'reward_per_opponent': array([-6.4, -6.3, -6.3, -6.4, -6.1, -6.5, -6.4, -6.5, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 122, num timesteps 8856000, FPS 765
 Last 1800 training episodes: mean/median reward -4.9278/-4.8650, min/max reward -5.6100/-4.3650
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.013888888888888888
 Evaluation using 45 episodes: {'reward': -6.311111111111111, 'reward_per_opponent': array([-6.1, -6.3, -6.3, -6.4, -6.3, -6.4, -6.7, -6.1, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 123, num timesteps 8928000, FPS 756
 Last 1800 training episodes: mean/median reward -4.8742/-4.8325, min/max reward -5.6250/-4.2800
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.011111111111111112
 Evaluation using 45 episodes: {'reward': -6.355555555555555, 'reward_per_opponent': array([-6.3, -6.3, -6.3, -6.4, -6.5, -6.3, -6.1, -6.5, -6.5]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 124, num timesteps 9000000, FPS 768
 Last 1800 training episodes: mean/median reward -4.7644/-4.6525, min/max reward -5.4100/-4.2450
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.002777777777777778
Updates 125, num timesteps 9072000, FPS 808
 Last 1800 training episodes: mean/median reward -4.7136/-4.6925, min/max reward -5.3850/-4.1700
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.002777777777777778
 Evaluation using 45 episodes: {'reward': -6.2, 'reward_per_opponent': array([-6. , -6.3, -5.9, -6.3, -6.4, -6.5, -6.2, -6. , -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 126, num timesteps 9144000, FPS 774
 Last 1800 training episodes: mean/median reward -4.6286/-4.6150, min/max reward -5.1550/-4.1450
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.008333333333333335
 Evaluation using 45 episodes: {'reward': -6.411111111111111, 'reward_per_opponent': array([-6.7, -6.3, -6.5, -6.2, -6.7, -6.2, -6.3, -6.5, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 127, num timesteps 9216000, FPS 773
 Last 1800 training episodes: mean/median reward -4.5422/-4.5075, min/max reward -5.1450/-4.1000
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 128, num timesteps 9288000, FPS 814
 Last 1800 training episodes: mean/median reward -4.4711/-4.4100, min/max reward -4.8300/-4.1200
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.355555555555555, 'reward_per_opponent': array([-6.2, -6.3, -6.3, -6.2, -6.4, -6.6, -6.6, -6.3, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 129, num timesteps 9360000, FPS 778
 Last 1800 training episodes: mean/median reward -4.4239/-4.3775, min/max reward -4.8800/-4.0150
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.300000000000001, 'reward_per_opponent': array([-6.2, -6.5, -6. , -6.4, -6.2, -6.4, -6.5, -6.2, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 130, num timesteps 9432000, FPS 765
 Last 1800 training episodes: mean/median reward -4.3833/-4.2850, min/max reward -4.7750/-4.0250
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.622222222222223, 'reward_per_opponent': array([-6.5, -6.6, -6.8, -6.8, -6.7, -6.6, -6.7, -6.4, -6.5]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 131, num timesteps 9504000, FPS 762
 Last 1800 training episodes: mean/median reward -4.3350/-4.2500, min/max reward -4.7050/-3.9650
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.005555555555555556
Updates 132, num timesteps 9576000, FPS 807
 Last 1800 training episodes: mean/median reward -4.3278/-4.2175, min/max reward -4.6750/-4.0300
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.002777777777777778
 Evaluation using 45 episodes: {'reward': -6.466666666666665, 'reward_per_opponent': array([-6.3, -6.6, -6.4, -6.3, -6.4, -6.8, -6.6, -6.5, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 133, num timesteps 9648000, FPS 766
 Last 1800 training episodes: mean/median reward -4.2778/-4.2550, min/max reward -4.5550/-3.9850
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.005555555555555556
 Evaluation using 45 episodes: {'reward': -6.433333333333334, 'reward_per_opponent': array([-6.5, -6.4, -6.5, -6.6, -6.5, -6.5, -6.3, -6.3, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 134, num timesteps 9720000, FPS 767
 Last 1800 training episodes: mean/median reward -4.1994/-4.2025, min/max reward -4.5350/-3.9150
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 135, num timesteps 9792000, FPS 803
 Last 1800 training episodes: mean/median reward -4.1753/-4.1150, min/max reward -4.4900/-3.8700
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.002777777777777778
 Evaluation using 45 episodes: {'reward': -6.333333333333333, 'reward_per_opponent': array([-6.5, -6.3, -6.3, -6.3, -6.6, -6.3, -6.1, -6.1, -6.5]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 136, num timesteps 9864000, FPS 771
 Last 1800 training episodes: mean/median reward -4.0964/-4.0750, min/max reward -4.3750/-3.8450
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.355555555555556, 'reward_per_opponent': array([-6.3, -6.5, -6.4, -6.5, -6.5, -6.1, -6.2, -6.3, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 137, num timesteps 9936000, FPS 766
 Last 1800 training episodes: mean/median reward -4.0964/-4.0375, min/max reward -4.3950/-3.8700
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.211111111111112, 'reward_per_opponent': array([-6.3, -6.5, -6.2, -6.1, -6.1, -6.2, -6.2, -6.3, -6. ]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 138, num timesteps 10008000, FPS 771
 Last 1800 training episodes: mean/median reward -4.0653/-4.0700, min/max reward -4.2650/-3.8650
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.002777777777777778
Model saved.
Updates 139, num timesteps 10080000, FPS 815
 Last 1800 training episodes: mean/median reward -4.0003/-3.9750, min/max reward -4.1800/-3.7850
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.002777777777777778
 Evaluation using 45 episodes: {'reward': -6.2, 'reward_per_opponent': array([-6.4, -6.1, -6. , -6.1, -6.2, -6.3, -5.9, -6.6, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 140, num timesteps 10152000, FPS 768
 Last 1800 training episodes: mean/median reward -3.9839/-3.9525, min/max reward -4.2150/-3.8300
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.2555555555555555, 'reward_per_opponent': array([-6.4, -6.2, -6.2, -6.2, -6.1, -6.3, -6.3, -6.2, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 141, num timesteps 10224000, FPS 750
 Last 1800 training episodes: mean/median reward -3.9647/-3.9575, min/max reward -4.2050/-3.7250
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 142, num timesteps 10296000, FPS 804
 Last 1800 training episodes: mean/median reward -3.9222/-3.9200, min/max reward -4.0750/-3.7600
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.133333333333334, 'reward_per_opponent': array([-6.4, -6. , -6.1, -6.1, -6. , -6.3, -5.9, -6. , -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 143, num timesteps 10368000, FPS 767
 Last 1800 training episodes: mean/median reward -3.8856/-3.8450, min/max reward -4.1450/-3.7250
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.002777777777777778
 Evaluation using 45 episodes: {'reward': -6.122222222222223, 'reward_per_opponent': array([-6.2, -5.9, -6.1, -6.4, -6.1, -6.3, -6.2, -5.9, -6. ]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 144, num timesteps 10440000, FPS 765
 Last 1800 training episodes: mean/median reward -3.8642/-3.8275, min/max reward -4.0400/-3.6450
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.002777777777777778
 Evaluation using 45 episodes: {'reward': -6.022222222222222, 'reward_per_opponent': array([-6. , -5.7, -6.3, -6.1, -6. , -5.9, -6.3, -5.8, -6.1]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 145, num timesteps 10512000, FPS 767
 Last 1800 training episodes: mean/median reward -3.8550/-3.8300, min/max reward -4.0800/-3.6100
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 146, num timesteps 10584000, FPS 801
 Last 1800 training episodes: mean/median reward -3.8419/-3.8050, min/max reward -4.0450/-3.6650
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.002777777777777778
 Evaluation using 45 episodes: {'reward': -6.055555555555555, 'reward_per_opponent': array([-6.2, -6.2, -5.9, -6. , -6. , -6.1, -6. , -5.9, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 147, num timesteps 10656000, FPS 756
 Last 1800 training episodes: mean/median reward -3.8136/-3.8175, min/max reward -3.9200/-3.7000
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.002777777777777778
 Evaluation using 45 episodes: {'reward': -5.988888888888889, 'reward_per_opponent': array([-6.1, -6.1, -5.8, -6. , -6.1, -6.1, -6. , -5.9, -5.8]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 148, num timesteps 10728000, FPS 758
 Last 1800 training episodes: mean/median reward -3.8006/-3.8000, min/max reward -4.0200/-3.6250
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.002777777777777778
 Evaluation using 45 episodes: {'reward': -6.111111111111111, 'reward_per_opponent': array([-6.1, -6. , -6.2, -6.1, -6.1, -6. , -6.4, -6. , -6.1]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 149, num timesteps 10800000, FPS 769
 Last 1800 training episodes: mean/median reward -3.7872/-3.7750, min/max reward -4.0100/-3.6150
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.002777777777777778
Updates 150, num timesteps 10872000, FPS 804
 Last 1800 training episodes: mean/median reward -3.7564/-3.7425, min/max reward -3.9550/-3.5650
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.044444444444444, 'reward_per_opponent': array([-6. , -5.9, -6.2, -6. , -6.3, -6.2, -6. , -6. , -5.8]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 151, num timesteps 10944000, FPS 726
 Last 1800 training episodes: mean/median reward -3.7494/-3.7475, min/max reward -3.9500/-3.4750
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.002777777777777778
 Evaluation using 45 episodes: {'reward': -6.077777777777778, 'reward_per_opponent': array([-6. , -6.2, -6.3, -6. , -5.9, -6. , -6. , -6.3, -6. ]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 152, num timesteps 11016000, FPS 734
 Last 1800 training episodes: mean/median reward -3.6997/-3.7025, min/max reward -3.8450/-3.5000
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 153, num timesteps 11088000, FPS 795
 Last 1800 training episodes: mean/median reward -3.6881/-3.6725, min/max reward -3.8950/-3.5300
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -5.977777777777778, 'reward_per_opponent': array([-6. , -5.8, -6. , -6. , -6.1, -6.1, -5.9, -6.1, -5.8]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 154, num timesteps 11160000, FPS 769
 Last 1800 training episodes: mean/median reward -3.6833/-3.6400, min/max reward -3.9050/-3.5150
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.133333333333334, 'reward_per_opponent': array([-5.6, -6.1, -6.1, -6.2, -6.2, -6.4, -6.1, -6.3, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 155, num timesteps 11232000, FPS 762
 Last 1800 training episodes: mean/median reward -3.6661/-3.6300, min/max reward -3.8100/-3.5600
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -5.977777777777778, 'reward_per_opponent': array([-5.8, -5.8, -6.1, -6.1, -5.8, -5.9, -6. , -6.2, -6.1]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 156, num timesteps 11304000, FPS 757
 Last 1800 training episodes: mean/median reward -3.6636/-3.6525, min/max reward -3.8200/-3.5300
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.005555555555555556
Updates 157, num timesteps 11376000, FPS 810
 Last 1800 training episodes: mean/median reward -3.6739/-3.6750, min/max reward -3.7950/-3.5450
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.002777777777777778
 Evaluation using 45 episodes: {'reward': -6.088888888888889, 'reward_per_opponent': array([-6. , -5.9, -6.1, -6.3, -6.1, -6.1, -6.1, -6. , -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 158, num timesteps 11448000, FPS 766
 Last 1800 training episodes: mean/median reward -3.6375/-3.6400, min/max reward -3.8350/-3.5100
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.002777777777777778
 Evaluation using 45 episodes: {'reward': -6.0888888888888895, 'reward_per_opponent': array([-6.2, -6.3, -6.1, -6. , -6.1, -6.2, -5.8, -6. , -6.1]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 159, num timesteps 11520000, FPS 765
 Last 1800 training episodes: mean/median reward -3.6125/-3.6025, min/max reward -3.8000/-3.4550
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.002777777777777778
Updates 160, num timesteps 11592000, FPS 800
 Last 1800 training episodes: mean/median reward -3.6106/-3.6075, min/max reward -3.7100/-3.4800
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.066666666666666, 'reward_per_opponent': array([-6.2, -6.2, -5.9, -6. , -6.1, -5.9, -6. , -6.3, -6. ]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 161, num timesteps 11664000, FPS 770
 Last 1800 training episodes: mean/median reward -3.5756/-3.5700, min/max reward -3.7400/-3.4400
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.044444444444444, 'reward_per_opponent': array([-6.2, -6. , -6. , -6. , -6.1, -6.1, -6.1, -6. , -5.9]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 162, num timesteps 11736000, FPS 768
 Last 1800 training episodes: mean/median reward -3.5639/-3.5475, min/max reward -3.7050/-3.4850
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.144444444444444, 'reward_per_opponent': array([-6.1, -6.3, -6. , -6.2, -6.1, -6.2, -6.2, -6.2, -6. ]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 163, num timesteps 11808000, FPS 760
 Last 1800 training episodes: mean/median reward -3.5733/-3.5675, min/max reward -3.7450/-3.4700
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.005555555555555556
Updates 164, num timesteps 11880000, FPS 803
 Last 1800 training episodes: mean/median reward -3.5492/-3.5200, min/max reward -3.6950/-3.4400
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.002777777777777778
 Evaluation using 45 episodes: {'reward': -6.088888888888889, 'reward_per_opponent': array([-5.9, -6.1, -6.1, -6.1, -6.3, -5.9, -6. , -6.2, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 165, num timesteps 11952000, FPS 777
 Last 1800 training episodes: mean/median reward -3.5425/-3.5200, min/max reward -3.7000/-3.4200
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.033333333333334, 'reward_per_opponent': array([-6.2, -6. , -5.9, -6. , -5.9, -5.7, -6.2, -6.2, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 166, num timesteps 12024000, FPS 765
 Last 1800 training episodes: mean/median reward -3.5261/-3.5000, min/max reward -3.7050/-3.3900
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 167, num timesteps 12096000, FPS 798
 Last 1800 training episodes: mean/median reward -3.5200/-3.5000, min/max reward -3.7100/-3.4100
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.0777777777777775, 'reward_per_opponent': array([-6. , -6. , -6.1, -6.1, -6.1, -6.1, -6.1, -6.1, -6.1]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 168, num timesteps 12168000, FPS 722
 Last 1800 training episodes: mean/median reward -3.5214/-3.5050, min/max reward -3.6950/-3.3900
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.002777777777777778
 Evaluation using 45 episodes: {'reward': -6.199999999999999, 'reward_per_opponent': array([-6.2, -6.1, -6.5, -6.1, -6.3, -6.3, -6. , -6.2, -6.1]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 169, num timesteps 12240000, FPS 770
 Last 1800 training episodes: mean/median reward -3.5336/-3.5425, min/max reward -3.6400/-3.4000
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.022222222222222, 'reward_per_opponent': array([-5.9, -6. , -6. , -6. , -5.9, -5.9, -6.2, -6.1, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 170, num timesteps 12312000, FPS 774
 Last 1800 training episodes: mean/median reward -3.5442/-3.5350, min/max reward -3.6500/-3.4300
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 171, num timesteps 12384000, FPS 801
 Last 1800 training episodes: mean/median reward -3.5300/-3.5200, min/max reward -3.6500/-3.4300
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.188888888888889, 'reward_per_opponent': array([-6. , -6.4, -6.1, -6. , -6.2, -6.4, -6.1, -6.4, -6.1]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 172, num timesteps 12456000, FPS 705
 Last 1800 training episodes: mean/median reward -3.5344/-3.5350, min/max reward -3.6700/-3.3900
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.111111111111111, 'reward_per_opponent': array([-6.2, -5.9, -5.9, -6.1, -6.3, -5.9, -6.3, -6.1, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 173, num timesteps 12528000, FPS 741
 Last 1800 training episodes: mean/median reward -3.5431/-3.5500, min/max reward -3.6750/-3.4550
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.133333333333332, 'reward_per_opponent': array([-6. , -6.1, -6. , -6.2, -6.1, -6.3, -6. , -6.2, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 174, num timesteps 12600000, FPS 757
 Last 1800 training episodes: mean/median reward -3.5158/-3.5175, min/max reward -3.6150/-3.4100
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 175, num timesteps 12672000, FPS 814
 Last 1800 training episodes: mean/median reward -3.5289/-3.5350, min/max reward -3.6400/-3.3950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.166666666666667, 'reward_per_opponent': array([-6. , -6.6, -6.3, -5.9, -6.1, -6. , -6.2, -6.2, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 176, num timesteps 12744000, FPS 766
 Last 1800 training episodes: mean/median reward -3.5150/-3.5250, min/max reward -3.5950/-3.4000
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.066666666666666, 'reward_per_opponent': array([-6. , -5.9, -6.1, -6.2, -6.3, -5.9, -6.1, -6. , -6.1]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 177, num timesteps 12816000, FPS 770
 Last 1800 training episodes: mean/median reward -3.5106/-3.4975, min/max reward -3.6100/-3.4400
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 178, num timesteps 12888000, FPS 819
 Last 1800 training episodes: mean/median reward -3.5081/-3.5125, min/max reward -3.6250/-3.3800
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.002777777777777778
 Evaluation using 45 episodes: {'reward': -5.944444444444444, 'reward_per_opponent': array([-5.9, -6. , -5.8, -5.7, -6. , -5.9, -6.1, -6.3, -5.8]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 179, num timesteps 12960000, FPS 774
 Last 1800 training episodes: mean/median reward -3.5125/-3.5100, min/max reward -3.6750/-3.4050
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -5.944444444444445, 'reward_per_opponent': array([-6. , -5.8, -5.8, -6. , -5.9, -6.1, -6.1, -6. , -5.8]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 180, num timesteps 13032000, FPS 770
 Last 1800 training episodes: mean/median reward -3.4925/-3.4750, min/max reward -3.6850/-3.4000
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.044444444444444, 'reward_per_opponent': array([-6.1, -6. , -5.8, -5.9, -6. , -6.2, -6.1, -6.2, -6.1]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 181, num timesteps 13104000, FPS 774
 Last 1800 training episodes: mean/median reward -3.4967/-3.4975, min/max reward -3.6600/-3.3600
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 182, num timesteps 13176000, FPS 797
 Last 1800 training episodes: mean/median reward -3.4828/-3.4875, min/max reward -3.5950/-3.3650
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.005555555555555556
 Evaluation using 45 episodes: {'reward': -6.044444444444444, 'reward_per_opponent': array([-5.9, -6. , -6.3, -6.1, -6.1, -5.8, -6.1, -6. , -6.1]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 183, num timesteps 13248000, FPS 763
 Last 1800 training episodes: mean/median reward -3.4814/-3.4875, min/max reward -3.5900/-3.3850
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.002777777777777778
 Evaluation using 45 episodes: {'reward': -6.322222222222222, 'reward_per_opponent': array([-6.3, -6.2, -6.3, -6.4, -6.3, -6.3, -6.3, -6.3, -6.5]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 184, num timesteps 13320000, FPS 762
 Last 1800 training episodes: mean/median reward -3.4664/-3.4625, min/max reward -3.5500/-3.3650
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.013888888888888888
Updates 185, num timesteps 13392000, FPS 806
 Last 1800 training episodes: mean/median reward -3.4561/-3.4550, min/max reward -3.5200/-3.3300
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.388888888888889, 'reward_per_opponent': array([-6.5, -6.4, -6.2, -6.4, -6.5, -6.4, -6.4, -6.4, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 186, num timesteps 13464000, FPS 768
 Last 1800 training episodes: mean/median reward -3.4608/-3.4650, min/max reward -3.5850/-3.3400
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.002777777777777778
 Evaluation using 45 episodes: {'reward': -6.311111111111112, 'reward_per_opponent': array([-6.4, -6.2, -6. , -6.6, -6.4, -6.2, -6.3, -6.3, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 187, num timesteps 13536000, FPS 755
 Last 1800 training episodes: mean/median reward -3.4511/-3.4475, min/max reward -3.5450/-3.3650
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.211111111111111, 'reward_per_opponent': array([-6.3, -6.2, -6.2, -6.2, -6.1, -6.3, -6.1, -6.3, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 188, num timesteps 13608000, FPS 767
 Last 1800 training episodes: mean/median reward -3.4375/-3.4425, min/max reward -3.5100/-3.3750
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 189, num timesteps 13680000, FPS 806
 Last 1800 training episodes: mean/median reward -3.4525/-3.4500, min/max reward -3.5850/-3.3750
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.266666666666667, 'reward_per_opponent': array([-6.3, -6.3, -6.3, -6.2, -6.3, -6.2, -6.2, -6.2, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 190, num timesteps 13752000, FPS 724
 Last 1800 training episodes: mean/median reward -3.4317/-3.4175, min/max reward -3.5650/-3.3500
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.333333333333333, 'reward_per_opponent': array([-6.4, -6.4, -6.5, -6.3, -6.3, -6.2, -6.1, -6.4, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 191, num timesteps 13824000, FPS 756
 Last 1800 training episodes: mean/median reward -3.4183/-3.4200, min/max reward -3.5000/-3.3300
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 192, num timesteps 13896000, FPS 808
 Last 1800 training episodes: mean/median reward -3.4414/-3.4500, min/max reward -3.5450/-3.3350
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.0888888888888895, 'reward_per_opponent': array([-6.2, -5.8, -6.1, -6.1, -6.1, -6. , -6.1, -6.3, -6.1]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 193, num timesteps 13968000, FPS 764
 Last 1800 training episodes: mean/median reward -3.4397/-3.4375, min/max reward -3.5300/-3.3400
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.166666666666667, 'reward_per_opponent': array([-6.3, -6.1, -6. , -6. , -6.2, -6.2, -6.2, -6.1, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 194, num timesteps 14040000, FPS 770
 Last 1800 training episodes: mean/median reward -3.4339/-3.4200, min/max reward -3.5400/-3.3300
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.2444444444444445, 'reward_per_opponent': array([-6.2, -6.3, -6.4, -6.1, -6.3, -6.1, -6.3, -6.3, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 195, num timesteps 14112000, FPS 768
 Last 1800 training episodes: mean/median reward -3.4219/-3.4225, min/max reward -3.5050/-3.3250
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 196, num timesteps 14184000, FPS 807
 Last 1800 training episodes: mean/median reward -3.4511/-3.4525, min/max reward -3.5550/-3.3350
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.366666666666667, 'reward_per_opponent': array([-6.1, -6.5, -6.5, -6.5, -6.3, -6.5, -6.2, -6.3, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 197, num timesteps 14256000, FPS 767
 Last 1800 training episodes: mean/median reward -3.4506/-3.4550, min/max reward -3.5700/-3.3600
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.005555555555555556
 Evaluation using 45 episodes: {'reward': -6.3999999999999995, 'reward_per_opponent': array([-6.5, -6.5, -6.3, -6.5, -6.3, -6.4, -6.3, -6.3, -6.5]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 198, num timesteps 14328000, FPS 762
 Last 1800 training episodes: mean/median reward -3.4519/-3.4400, min/max reward -3.5450/-3.3650
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.005555555555555556
 Evaluation using 45 episodes: {'reward': -6.3999999999999995, 'reward_per_opponent': array([-6.4, -6.4, -6.2, -6.4, -6.5, -6.4, -6.5, -6.5, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 199, num timesteps 14400000, FPS 766
 Last 1800 training episodes: mean/median reward -3.4542/-3.4450, min/max reward -3.5250/-3.3800
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.002777777777777778
Updates 200, num timesteps 14472000, FPS 809
 Last 1800 training episodes: mean/median reward -3.4389/-3.4500, min/max reward -3.5000/-3.3650
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.377777777777777, 'reward_per_opponent': array([-6.2, -6.4, -6.4, -6.5, -6.4, -6.5, -6.3, -6.4, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 201, num timesteps 14544000, FPS 763
 Last 1800 training episodes: mean/median reward -3.4375/-3.4300, min/max reward -3.5250/-3.3350
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.4, 'reward_per_opponent': array([-6.5, -6.4, -6.3, -6.2, -6.4, -6.4, -6.5, -6.5, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 202, num timesteps 14616000, FPS 745
 Last 1800 training episodes: mean/median reward -3.4528/-3.4550, min/max reward -3.5150/-3.4000
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 203, num timesteps 14688000, FPS 807
 Last 1800 training episodes: mean/median reward -3.4356/-3.4375, min/max reward -3.5300/-3.3450
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.444444444444445, 'reward_per_opponent': array([-6.4, -6.3, -6.6, -6.5, -6.3, -6.5, -6.4, -6.5, -6.5]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 204, num timesteps 14760000, FPS 770
 Last 1800 training episodes: mean/median reward -3.4283/-3.4275, min/max reward -3.5050/-3.3400
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.4111111111111105, 'reward_per_opponent': array([-6.5, -6.5, -6.4, -6.3, -6.5, -6.5, -6.3, -6.4, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 205, num timesteps 14832000, FPS 759
 Last 1800 training episodes: mean/median reward -3.4500/-3.4425, min/max reward -3.5200/-3.4000
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.477777777777778, 'reward_per_opponent': array([-6.4, -6.7, -6.5, -6.6, -6.5, -6.4, -6.5, -6.4, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 206, num timesteps 14904000, FPS 757
 Last 1800 training episodes: mean/median reward -3.4383/-3.4275, min/max reward -3.5700/-3.3050
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 207, num timesteps 14976000, FPS 806
 Last 1800 training episodes: mean/median reward -3.4578/-3.4425, min/max reward -3.5450/-3.3500
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.377777777777777, 'reward_per_opponent': array([-6.4, -6.4, -6.4, -6.1, -6.5, -6.3, -6.6, -6.3, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 208, num timesteps 15048000, FPS 770
 Last 1800 training episodes: mean/median reward -3.4217/-3.4225, min/max reward -3.5400/-3.3450
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Model saved.
 Evaluation using 45 episodes: {'reward': -6.466666666666666, 'reward_per_opponent': array([-6.6, -6.3, -6.5, -6.3, -6.5, -6.6, -6.5, -6.5, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 209, num timesteps 15120000, FPS 748
 Last 1800 training episodes: mean/median reward -3.4464/-3.4500, min/max reward -3.5200/-3.3350
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 210, num timesteps 15192000, FPS 811
 Last 1800 training episodes: mean/median reward -3.4556/-3.4575, min/max reward -3.6100/-3.3200
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.011111111111111112
 Evaluation using 45 episodes: {'reward': -6.444444444444445, 'reward_per_opponent': array([-6.5, -6.3, -6.5, -6.4, -6.5, -6.4, -6.4, -6.5, -6.5]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 211, num timesteps 15264000, FPS 759
 Last 1800 training episodes: mean/median reward -3.4356/-3.4200, min/max reward -3.5450/-3.3550
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.5, 'reward_per_opponent': array([-6.5, -6.4, -6.6, -6.6, -6.6, -6.5, -6.4, -6.4, -6.5]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 212, num timesteps 15336000, FPS 768
 Last 1800 training episodes: mean/median reward -3.4361/-3.4275, min/max reward -3.5800/-3.3300
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.5, 'reward_per_opponent': array([-6.6, -6.5, -6.5, -6.4, -6.6, -6.6, -6.5, -6.4, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 213, num timesteps 15408000, FPS 737
 Last 1800 training episodes: mean/median reward -3.4206/-3.4225, min/max reward -3.5300/-3.3150
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 214, num timesteps 15480000, FPS 815
 Last 1800 training episodes: mean/median reward -3.4125/-3.4075, min/max reward -3.4800/-3.3350
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.444444444444445, 'reward_per_opponent': array([-6.4, -6.5, -6.4, -6.4, -6.4, -6.5, -6.5, -6.4, -6.5]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 215, num timesteps 15552000, FPS 774
 Last 1800 training episodes: mean/median reward -3.3881/-3.3850, min/max reward -3.4400/-3.2900
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.4111111111111105, 'reward_per_opponent': array([-6.3, -6.4, -6.4, -6.2, -6.4, -6.5, -6.6, -6.5, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 216, num timesteps 15624000, FPS 774
 Last 1800 training episodes: mean/median reward -3.4203/-3.4225, min/max reward -3.5050/-3.3300
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 217, num timesteps 15696000, FPS 789
 Last 1800 training episodes: mean/median reward -3.4103/-3.4150, min/max reward -3.4700/-3.3450
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.444444444444445, 'reward_per_opponent': array([-6.6, -6.5, -6.4, -6.4, -6.4, -6.4, -6.6, -6.1, -6.6]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 218, num timesteps 15768000, FPS 767
 Last 1800 training episodes: mean/median reward -3.4006/-3.3975, min/max reward -3.4650/-3.3350
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.002777777777777778
 Evaluation using 45 episodes: {'reward': -6.311111111111111, 'reward_per_opponent': array([-6.4, -6.4, -6.3, -6.4, -6.4, -6.4, -6. , -6.2, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 219, num timesteps 15840000, FPS 697
 Last 1800 training episodes: mean/median reward -3.3989/-3.4025, min/max reward -3.4800/-3.3250
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.433333333333334, 'reward_per_opponent': array([-6.4, -6.1, -6.4, -6.5, -6.5, -6.5, -6.5, -6.5, -6.5]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 220, num timesteps 15912000, FPS 705
 Last 1800 training episodes: mean/median reward -3.3800/-3.3700, min/max reward -3.4600/-3.2900
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 221, num timesteps 15984000, FPS 796
 Last 1800 training episodes: mean/median reward -3.3817/-3.3800, min/max reward -3.4800/-3.2750
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.377777777777777, 'reward_per_opponent': array([-6.2, -6.5, -6.5, -6.3, -6.4, -6.5, -6.4, -6.3, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 222, num timesteps 16056000, FPS 776
 Last 1800 training episodes: mean/median reward -3.3708/-3.3775, min/max reward -3.4100/-3.2850
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.366666666666666, 'reward_per_opponent': array([-6.4, -6.5, -6.3, -6.2, -6.4, -6.3, -6.4, -6.4, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 223, num timesteps 16128000, FPS 780
 Last 1800 training episodes: mean/median reward -3.3908/-3.4025, min/max reward -3.4400/-3.3050
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.444444444444445, 'reward_per_opponent': array([-6.5, -6.3, -6.5, -6.6, -6.5, -6.3, -6.3, -6.4, -6.6]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 224, num timesteps 16200000, FPS 780
 Last 1800 training episodes: mean/median reward -3.3828/-3.3800, min/max reward -3.5300/-3.2850
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 225, num timesteps 16272000, FPS 818
 Last 1800 training episodes: mean/median reward -3.4064/-3.3950, min/max reward -3.5000/-3.3300
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.005555555555555556
 Evaluation using 45 episodes: {'reward': -6.333333333333333, 'reward_per_opponent': array([-6.3, -6.4, -6.2, -6.4, -6.4, -6.2, -6.5, -6.3, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 226, num timesteps 16344000, FPS 775
 Last 1800 training episodes: mean/median reward -3.3853/-3.3825, min/max reward -3.4750/-3.2850
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.300000000000001, 'reward_per_opponent': array([-6.3, -6. , -6.5, -6.4, -6.3, -6. , -6.3, -6.3, -6.6]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 227, num timesteps 16416000, FPS 769
 Last 1800 training episodes: mean/median reward -3.3750/-3.3775, min/max reward -3.4450/-3.3000
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 228, num timesteps 16488000, FPS 803
 Last 1800 training episodes: mean/median reward -3.3778/-3.3850, min/max reward -3.4200/-3.3150
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.466666666666666, 'reward_per_opponent': array([-6.4, -6.5, -6.7, -6.4, -6.4, -6.5, -6.6, -6.3, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 229, num timesteps 16560000, FPS 769
 Last 1800 training episodes: mean/median reward -3.3850/-3.3975, min/max reward -3.4550/-3.3050
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.422222222222222, 'reward_per_opponent': array([-6.6, -6.5, -6.4, -6.3, -6.5, -6.4, -6.4, -6.2, -6.5]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 230, num timesteps 16632000, FPS 752
 Last 1800 training episodes: mean/median reward -3.3856/-3.3875, min/max reward -3.4650/-3.2800
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.366666666666666, 'reward_per_opponent': array([-6.3, -6.4, -6.5, -6.3, -6.4, -6.3, -6.4, -6.3, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 231, num timesteps 16704000, FPS 757
 Last 1800 training episodes: mean/median reward -3.3794/-3.3750, min/max reward -3.4800/-3.2850
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 232, num timesteps 16776000, FPS 806
 Last 1800 training episodes: mean/median reward -3.3636/-3.3700, min/max reward -3.4650/-3.2700
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.344444444444445, 'reward_per_opponent': array([-6.4, -6.5, -6.3, -6.2, -6.2, -6.2, -6.4, -6.4, -6.5]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 233, num timesteps 16848000, FPS 765
 Last 1800 training episodes: mean/median reward -3.3869/-3.3900, min/max reward -3.4850/-3.2900
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.344444444444444, 'reward_per_opponent': array([-6.1, -6.4, -6.4, -6.3, -6.4, -6.3, -6.5, -6.4, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 234, num timesteps 16920000, FPS 766
 Last 1800 training episodes: mean/median reward -3.3697/-3.3725, min/max reward -3.4700/-3.3050
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 235, num timesteps 16992000, FPS 795
 Last 1800 training episodes: mean/median reward -3.3772/-3.3750, min/max reward -3.4550/-3.3000
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.4222222222222225, 'reward_per_opponent': array([-6.3, -6.2, -6.5, -6.5, -6.4, -6.4, -6.3, -6.6, -6.6]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 236, num timesteps 17064000, FPS 756
 Last 1800 training episodes: mean/median reward -3.3736/-3.3650, min/max reward -3.4750/-3.3000
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.355555555555555, 'reward_per_opponent': array([-6.5, -6. , -6.5, -6.5, -6.4, -6.3, -6.5, -6.2, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 237, num timesteps 17136000, FPS 767
 Last 1800 training episodes: mean/median reward -3.3617/-3.3450, min/max reward -3.4350/-3.3000
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.377777777777777, 'reward_per_opponent': array([-6.3, -6.5, -6.3, -6.4, -6.5, -6.5, -6.2, -6.4, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 238, num timesteps 17208000, FPS 752
 Last 1800 training episodes: mean/median reward -3.3728/-3.3625, min/max reward -3.5100/-3.3050
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 239, num timesteps 17280000, FPS 801
 Last 1800 training episodes: mean/median reward -3.3831/-3.3775, min/max reward -3.4900/-3.2950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.002777777777777778
 Evaluation using 45 episodes: {'reward': -6.355555555555555, 'reward_per_opponent': array([-6.3, -6.2, -6.4, -6.3, -6.5, -6.4, -6.5, -6.5, -6.1]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 240, num timesteps 17352000, FPS 760
 Last 1800 training episodes: mean/median reward -3.3819/-3.3825, min/max reward -3.4500/-3.3100
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.355555555555555, 'reward_per_opponent': array([-6.3, -6.4, -6.4, -6.3, -6.4, -6.3, -6.4, -6.4, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 241, num timesteps 17424000, FPS 764
 Last 1800 training episodes: mean/median reward -3.3814/-3.3750, min/max reward -3.4600/-3.3250
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 242, num timesteps 17496000, FPS 802
 Last 1800 training episodes: mean/median reward -3.3619/-3.3625, min/max reward -3.4050/-3.3100
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.366666666666667, 'reward_per_opponent': array([-6.4, -6.5, -6.4, -6.4, -6.5, -6.3, -6.5, -6.3, -6. ]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 243, num timesteps 17568000, FPS 738
 Last 1800 training episodes: mean/median reward -3.3669/-3.3650, min/max reward -3.4300/-3.2950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.333333333333333, 'reward_per_opponent': array([-6.4, -6.3, -6.3, -6.5, -6.4, -6.3, -6.3, -6.2, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 244, num timesteps 17640000, FPS 718
 Last 1800 training episodes: mean/median reward -3.3572/-3.3550, min/max reward -3.4500/-3.2700
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.322222222222222, 'reward_per_opponent': array([-6.4, -6.4, -6.3, -6.3, -6.3, -6.2, -6.3, -6.3, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 245, num timesteps 17712000, FPS 758
 Last 1800 training episodes: mean/median reward -3.3836/-3.3800, min/max reward -3.4650/-3.3100
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 246, num timesteps 17784000, FPS 799
 Last 1800 training episodes: mean/median reward -3.3686/-3.3600, min/max reward -3.4600/-3.2900
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.411111111111111, 'reward_per_opponent': array([-6.5, -6.3, -6.4, -6.4, -6.5, -6.5, -6.4, -6.4, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 247, num timesteps 17856000, FPS 761
 Last 1800 training episodes: mean/median reward -3.3753/-3.3800, min/max reward -3.4650/-3.3150
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.366666666666666, 'reward_per_opponent': array([-6.3, -6.4, -6.3, -6.3, -6.3, -6.3, -6.5, -6.5, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 248, num timesteps 17928000, FPS 771
 Last 1800 training episodes: mean/median reward -3.3731/-3.3650, min/max reward -3.4200/-3.3300
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.4111111111111105, 'reward_per_opponent': array([-6.6, -6.4, -6.4, -6.4, -6.3, -6.4, -6.4, -6.4, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 249, num timesteps 18000000, FPS 765
 Last 1800 training episodes: mean/median reward -3.3731/-3.3650, min/max reward -3.4250/-3.2650
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 250, num timesteps 18072000, FPS 807
 Last 1800 training episodes: mean/median reward -3.3600/-3.3450, min/max reward -3.4650/-3.2050
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.444444444444445, 'reward_per_opponent': array([-6.5, -6.5, -6.4, -6.3, -6.4, -6.4, -6.4, -6.6, -6.5]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 251, num timesteps 18144000, FPS 765
 Last 1800 training episodes: mean/median reward -3.3489/-3.3500, min/max reward -3.4050/-3.2700
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.4, 'reward_per_opponent': array([-6.5, -6.3, -6.5, -6.5, -6.4, -6.2, -6.4, -6.3, -6.5]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 252, num timesteps 18216000, FPS 767
 Last 1800 training episodes: mean/median reward -3.3511/-3.3475, min/max reward -3.4950/-3.2700
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 253, num timesteps 18288000, FPS 809
 Last 1800 training episodes: mean/median reward -3.3517/-3.3500, min/max reward -3.4250/-3.2600
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.411111111111111, 'reward_per_opponent': array([-6.4, -6.5, -6.4, -6.5, -6.4, -6.4, -6.5, -6.3, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 254, num timesteps 18360000, FPS 747
 Last 1800 training episodes: mean/median reward -3.3583/-3.3600, min/max reward -3.4250/-3.2950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.355555555555555, 'reward_per_opponent': array([-6.4, -6.5, -6.5, -6.1, -6.2, -6.4, -6.4, -6.3, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 255, num timesteps 18432000, FPS 758
 Last 1800 training episodes: mean/median reward -3.3439/-3.3575, min/max reward -3.4350/-3.2450
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.355555555555556, 'reward_per_opponent': array([-6.5, -6.5, -6.5, -6.2, -6.5, -6.3, -6.2, -6.3, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 256, num timesteps 18504000, FPS 766
 Last 1800 training episodes: mean/median reward -3.3406/-3.3350, min/max reward -3.4150/-3.2850
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 257, num timesteps 18576000, FPS 816
 Last 1800 training episodes: mean/median reward -3.3492/-3.3400, min/max reward -3.4650/-3.2750
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.4, 'reward_per_opponent': array([-6.4, -6.4, -6.5, -6.3, -6.1, -6.5, -6.3, -6.6, -6.5]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 258, num timesteps 18648000, FPS 765
 Last 1800 training episodes: mean/median reward -3.3519/-3.3525, min/max reward -3.4400/-3.2500
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.355555555555556, 'reward_per_opponent': array([-6.5, -6.2, -6.4, -6.2, -6.5, -6.4, -6.3, -6.4, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 259, num timesteps 18720000, FPS 761
 Last 1800 training episodes: mean/median reward -3.3508/-3.3400, min/max reward -3.4300/-3.3000
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 260, num timesteps 18792000, FPS 802
 Last 1800 training episodes: mean/median reward -3.3742/-3.3700, min/max reward -3.4450/-3.3150
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.388888888888889, 'reward_per_opponent': array([-6.3, -6.4, -6.3, -6.5, -6.4, -6.4, -6.4, -6.4, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 261, num timesteps 18864000, FPS 769
 Last 1800 training episodes: mean/median reward -3.3778/-3.3650, min/max reward -3.4550/-3.3200
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.422222222222222, 'reward_per_opponent': array([-6.5, -6.5, -6.5, -6.5, -6.4, -6.3, -6.3, -6.3, -6.5]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 262, num timesteps 18936000, FPS 758
 Last 1800 training episodes: mean/median reward -3.3694/-3.3575, min/max reward -3.4700/-3.3200
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.377777777777778, 'reward_per_opponent': array([-6.5, -6.3, -6.5, -6.4, -6.3, -6.3, -6.3, -6.3, -6.5]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 263, num timesteps 19008000, FPS 766
 Last 1800 training episodes: mean/median reward -3.3608/-3.3775, min/max reward -3.4650/-3.2700
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 264, num timesteps 19080000, FPS 805
 Last 1800 training episodes: mean/median reward -3.3706/-3.3675, min/max reward -3.5000/-3.2850
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.344444444444445, 'reward_per_opponent': array([-6.3, -6.2, -6.4, -6.3, -6.5, -6.3, -6.3, -6.4, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 265, num timesteps 19152000, FPS 769
 Last 1800 training episodes: mean/median reward -3.3403/-3.3400, min/max reward -3.4200/-3.2450
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.333333333333333, 'reward_per_opponent': array([-6.4, -6.4, -6.5, -6.3, -6.3, -6.1, -6.3, -6.4, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 266, num timesteps 19224000, FPS 772
 Last 1800 training episodes: mean/median reward -3.3553/-3.3525, min/max reward -3.4650/-3.2900
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 267, num timesteps 19296000, FPS 808
 Last 1800 training episodes: mean/median reward -3.3533/-3.3475, min/max reward -3.4400/-3.2750
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.333333333333333, 'reward_per_opponent': array([-6.3, -6.4, -6.4, -6.2, -6.4, -6.5, -6.2, -6.4, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 268, num timesteps 19368000, FPS 767
 Last 1800 training episodes: mean/median reward -3.3608/-3.3700, min/max reward -3.4200/-3.2800
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.455555555555556, 'reward_per_opponent': array([-6.4, -6.5, -6.7, -6.6, -6.4, -6.4, -6.3, -6.4, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 269, num timesteps 19440000, FPS 768
 Last 1800 training episodes: mean/median reward -3.3633/-3.3475, min/max reward -3.4750/-3.2800
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.355555555555556, 'reward_per_opponent': array([-6.6, -6.4, -6.3, -6.2, -6.3, -6.4, -6.4, -6.4, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 270, num timesteps 19512000, FPS 733
 Last 1800 training episodes: mean/median reward -3.3661/-3.3675, min/max reward -3.4500/-3.2650
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 271, num timesteps 19584000, FPS 797
 Last 1800 training episodes: mean/median reward -3.3539/-3.3475, min/max reward -3.4350/-3.2900
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.311111111111111, 'reward_per_opponent': array([-6.4, -6.5, -6.3, -6.2, -6.3, -6.2, -6.5, -6.2, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 272, num timesteps 19656000, FPS 770
 Last 1800 training episodes: mean/median reward -3.3717/-3.3850, min/max reward -3.4350/-3.2350
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.211111111111111, 'reward_per_opponent': array([-6.3, -6.3, -6.3, -6.2, -6.2, -6.3, -6.2, -6.2, -5.9]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 273, num timesteps 19728000, FPS 760
 Last 1800 training episodes: mean/median reward -3.3911/-3.3850, min/max reward -3.5700/-3.2550
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.233333333333334, 'reward_per_opponent': array([-6.4, -6.2, -6.3, -6. , -6.3, -6.2, -6.2, -6.3, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 274, num timesteps 19800000, FPS 753
 Last 1800 training episodes: mean/median reward -3.3892/-3.3700, min/max reward -3.5700/-3.3000
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 275, num timesteps 19872000, FPS 804
 Last 1800 training episodes: mean/median reward -3.3678/-3.3575, min/max reward -3.5400/-3.2650
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.300000000000001, 'reward_per_opponent': array([-6.4, -6.2, -6.3, -6.2, -6.3, -6.3, -6.5, -6.3, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 276, num timesteps 19944000, FPS 775
 Last 1800 training episodes: mean/median reward -3.3572/-3.3425, min/max reward -3.5000/-3.2450
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.28888888888889, 'reward_per_opponent': array([-6.4, -6.1, -6.3, -6.4, -6.3, -6.3, -6.2, -6.4, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 277, num timesteps 20016000, FPS 768
 Last 1800 training episodes: mean/median reward -3.3756/-3.3825, min/max reward -3.4750/-3.2750
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Model saved.
Updates 278, num timesteps 20088000, FPS 817
 Last 1800 training episodes: mean/median reward -3.3822/-3.3850, min/max reward -3.4500/-3.2750
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.244444444444444, 'reward_per_opponent': array([-6.2, -6.1, -6.3, -6.3, -6.4, -6.3, -6.1, -6.2, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 279, num timesteps 20160000, FPS 780
 Last 1800 training episodes: mean/median reward -3.3642/-3.3475, min/max reward -3.5150/-3.2850
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.1, 'reward_per_opponent': array([-6.3, -6.1, -6.3, -6. , -6.3, -6. , -5.9, -5.9, -6.1]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 280, num timesteps 20232000, FPS 771
 Last 1800 training episodes: mean/median reward -3.3556/-3.3525, min/max reward -3.4750/-3.2600
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.188888888888888, 'reward_per_opponent': array([-6.4, -6. , -6.3, -6.1, -6.2, -5.9, -6.2, -6.2, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 281, num timesteps 20304000, FPS 760
 Last 1800 training episodes: mean/median reward -3.3386/-3.3375, min/max reward -3.4050/-3.2950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 282, num timesteps 20376000, FPS 821
 Last 1800 training episodes: mean/median reward -3.3506/-3.3375, min/max reward -3.4300/-3.3000
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.266666666666667, 'reward_per_opponent': array([-6.4, -6.3, -6.3, -6.3, -6.2, -6.4, -6.1, -6.3, -6.1]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 283, num timesteps 20448000, FPS 776
 Last 1800 training episodes: mean/median reward -3.3778/-3.3900, min/max reward -3.4300/-3.2750
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.266666666666667, 'reward_per_opponent': array([-6.3, -6.3, -6.4, -6.3, -6.2, -6.3, -6.2, -6.3, -6.1]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 284, num timesteps 20520000, FPS 777
 Last 1800 training episodes: mean/median reward -3.3772/-3.3725, min/max reward -3.5000/-3.2750
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 285, num timesteps 20592000, FPS 818
 Last 1800 training episodes: mean/median reward -3.3819/-3.3700, min/max reward -3.4800/-3.2950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.188888888888889, 'reward_per_opponent': array([-6.3, -6. , -6.1, -6.3, -6.4, -6.3, -5.9, -6.2, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 286, num timesteps 20664000, FPS 756
 Last 1800 training episodes: mean/median reward -3.4019/-3.4000, min/max reward -3.5450/-3.3450
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.211111111111112, 'reward_per_opponent': array([-6.4, -6.3, -6. , -6.3, -6.3, -6. , -6.1, -6.3, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 287, num timesteps 20736000, FPS 699
 Last 1800 training episodes: mean/median reward -3.4153/-3.4125, min/max reward -3.5400/-3.2950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.233333333333333, 'reward_per_opponent': array([-6.3, -6.4, -6.1, -6.3, -6. , -6.3, -6.2, -6.1, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 288, num timesteps 20808000, FPS 770
 Last 1800 training episodes: mean/median reward -3.3781/-3.3825, min/max reward -3.4850/-3.2750
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 289, num timesteps 20880000, FPS 814
 Last 1800 training episodes: mean/median reward -3.3708/-3.3725, min/max reward -3.4350/-3.2900
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.255555555555556, 'reward_per_opponent': array([-6.2, -6.4, -6.1, -6.4, -6.3, -6.2, -6.3, -6.2, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 290, num timesteps 20952000, FPS 775
 Last 1800 training episodes: mean/median reward -3.3842/-3.3950, min/max reward -3.4450/-3.3250
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.166666666666667, 'reward_per_opponent': array([-6.1, -6.1, -6.1, -6.1, -6.2, -6.2, -6.2, -6.3, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 291, num timesteps 21024000, FPS 781
 Last 1800 training episodes: mean/median reward -3.3408/-3.3425, min/max reward -3.4850/-3.2500
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 292, num timesteps 21096000, FPS 805
 Last 1800 training episodes: mean/median reward -3.3611/-3.3525, min/max reward -3.4450/-3.2750
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.177777777777778, 'reward_per_opponent': array([-6.3, -6.1, -6.2, -6. , -6.2, -6.3, -6.1, -6.2, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 293, num timesteps 21168000, FPS 759
 Last 1800 training episodes: mean/median reward -3.3603/-3.3675, min/max reward -3.4050/-3.2500
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.322222222222221, 'reward_per_opponent': array([-6.3, -6.3, -6.3, -6.5, -6.3, -6.4, -6.3, -6.2, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 294, num timesteps 21240000, FPS 771
 Last 1800 training episodes: mean/median reward -3.3611/-3.3525, min/max reward -3.4300/-3.3100
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.333333333333334, 'reward_per_opponent': array([-6.3, -6.4, -6.2, -6.4, -6.4, -6.3, -6.5, -6.4, -6.1]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 295, num timesteps 21312000, FPS 765
 Last 1800 training episodes: mean/median reward -3.3469/-3.3500, min/max reward -3.4200/-3.2800
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 296, num timesteps 21384000, FPS 811
 Last 1800 training episodes: mean/median reward -3.3336/-3.3375, min/max reward -3.4150/-3.2450
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.2444444444444445, 'reward_per_opponent': array([-6.2, -6.3, -6.3, -6.2, -6.4, -6.2, -6.3, -6.2, -6.1]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 297, num timesteps 21456000, FPS 776
 Last 1800 training episodes: mean/median reward -3.3511/-3.3650, min/max reward -3.4350/-3.2600
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.288888888888889, 'reward_per_opponent': array([-6.5, -6.4, -6.3, -6.1, -6.3, -6.3, -6.3, -6.3, -6.1]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 298, num timesteps 21528000, FPS 772
 Last 1800 training episodes: mean/median reward -3.3647/-3.3650, min/max reward -3.4450/-3.2900
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.2666666666666675, 'reward_per_opponent': array([-6.3, -6.3, -6.2, -6.3, -6. , -6.4, -6.3, -6.4, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 299, num timesteps 21600000, FPS 750
 Last 1800 training episodes: mean/median reward -3.3683/-3.3825, min/max reward -3.4500/-3.2950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 300, num timesteps 21672000, FPS 800
 Last 1800 training episodes: mean/median reward -3.3575/-3.3550, min/max reward -3.4750/-3.2600
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.233333333333333, 'reward_per_opponent': array([-6. , -6.4, -6.3, -6.3, -6.2, -6.2, -6.4, -6.1, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 301, num timesteps 21744000, FPS 762
 Last 1800 training episodes: mean/median reward -3.3397/-3.3375, min/max reward -3.4050/-3.2500
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.188888888888889, 'reward_per_opponent': array([-6.2, -6.3, -6.2, -6. , -6.3, -6.2, -6. , -6.3, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 302, num timesteps 21816000, FPS 770
 Last 1800 training episodes: mean/median reward -3.3306/-3.3400, min/max reward -3.3950/-3.2250
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 303, num timesteps 21888000, FPS 790
 Last 1800 training episodes: mean/median reward -3.3572/-3.3500, min/max reward -3.5050/-3.2650
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.322222222222222, 'reward_per_opponent': array([-6.2, -6.5, -6.3, -6.3, -6.1, -6.4, -6.3, -6.4, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 304, num timesteps 21960000, FPS 751
 Last 1800 training episodes: mean/median reward -3.3500/-3.3475, min/max reward -3.4150/-3.2950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.255555555555556, 'reward_per_opponent': array([-6.3, -6.1, -6.4, -6.3, -6.4, -6.2, -6.3, -6.2, -6.1]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 305, num timesteps 22032000, FPS 775
 Last 1800 training episodes: mean/median reward -3.3397/-3.3350, min/max reward -3.4050/-3.2650
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.288888888888889, 'reward_per_opponent': array([-6.2, -6.3, -6.2, -6.2, -6.3, -6.4, -6.2, -6.4, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 306, num timesteps 22104000, FPS 705
 Last 1800 training episodes: mean/median reward -3.3436/-3.3525, min/max reward -3.4150/-3.2450
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 307, num timesteps 22176000, FPS 808
 Last 1800 training episodes: mean/median reward -3.3331/-3.3300, min/max reward -3.4300/-3.2550
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.211111111111111, 'reward_per_opponent': array([-6.4, -6.3, -6.1, -6. , -6. , -6.1, -6.3, -6.3, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 308, num timesteps 22248000, FPS 751
 Last 1800 training episodes: mean/median reward -3.3358/-3.3350, min/max reward -3.3900/-3.2750
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.388888888888889, 'reward_per_opponent': array([-6.4, -6.2, -6.4, -6.5, -6.4, -6.3, -6.5, -6.4, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 309, num timesteps 22320000, FPS 771
 Last 1800 training episodes: mean/median reward -3.3297/-3.3325, min/max reward -3.4100/-3.2700
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 310, num timesteps 22392000, FPS 807
 Last 1800 training episodes: mean/median reward -3.3369/-3.3325, min/max reward -3.3950/-3.2550
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.188888888888889, 'reward_per_opponent': array([-6.1, -6.2, -6.1, -6.2, -6.3, -6.3, -6.2, -6.1, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 311, num timesteps 22464000, FPS 767
 Last 1800 training episodes: mean/median reward -3.3558/-3.3750, min/max reward -3.4400/-3.2700
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.166666666666667, 'reward_per_opponent': array([-6. , -6.1, -6.1, -6.1, -6.2, -6.1, -6.4, -6.2, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 312, num timesteps 22536000, FPS 746
 Last 1800 training episodes: mean/median reward -3.3517/-3.3475, min/max reward -3.4150/-3.2700
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.133333333333334, 'reward_per_opponent': array([-6.2, -6.2, -6.2, -6. , -6.2, -6. , -6.3, -6.1, -6. ]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 313, num timesteps 22608000, FPS 759
 Last 1800 training episodes: mean/median reward -3.3306/-3.3175, min/max reward -3.4150/-3.2500
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 314, num timesteps 22680000, FPS 804
 Last 1800 training episodes: mean/median reward -3.3286/-3.3300, min/max reward -3.4000/-3.2500
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.311111111111111, 'reward_per_opponent': array([-6.4, -6.3, -6.3, -6.3, -6.3, -6.5, -6.3, -6.2, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 315, num timesteps 22752000, FPS 772
 Last 1800 training episodes: mean/median reward -3.3278/-3.3350, min/max reward -3.4000/-3.2450
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.377777777777777, 'reward_per_opponent': array([-6.4, -6.4, -6.4, -6.4, -6.6, -6.3, -6.2, -6.2, -6.5]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 316, num timesteps 22824000, FPS 744
 Last 1800 training episodes: mean/median reward -3.3597/-3.3450, min/max reward -3.4300/-3.2700
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 317, num timesteps 22896000, FPS 799
 Last 1800 training episodes: mean/median reward -3.3836/-3.3825, min/max reward -3.4900/-3.2650
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.344444444444444, 'reward_per_opponent': array([-6.4, -6.3, -6.3, -6.3, -6.4, -6.4, -6.3, -6.4, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 318, num timesteps 22968000, FPS 762
 Last 1800 training episodes: mean/median reward -3.3761/-3.3700, min/max reward -3.4500/-3.2800
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.333333333333333, 'reward_per_opponent': array([-6.3, -6.3, -6.4, -6.3, -6.5, -6.3, -6.4, -6.3, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 319, num timesteps 23040000, FPS 774
 Last 1800 training episodes: mean/median reward -3.3667/-3.3550, min/max reward -3.4500/-3.2900
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.333333333333333, 'reward_per_opponent': array([-6.3, -6.5, -6.4, -6.2, -6.3, -6.3, -6.4, -6.4, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 320, num timesteps 23112000, FPS 776
 Last 1800 training episodes: mean/median reward -3.3639/-3.3750, min/max reward -3.4150/-3.2900
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 321, num timesteps 23184000, FPS 833
 Last 1800 training episodes: mean/median reward -3.3664/-3.3650, min/max reward -3.4300/-3.3100
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.377777777777777, 'reward_per_opponent': array([-6.2, -6.6, -6.3, -6.4, -6.5, -6.3, -6.3, -6.4, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 322, num timesteps 23256000, FPS 764
 Last 1800 training episodes: mean/median reward -3.3781/-3.3650, min/max reward -3.4600/-3.3250
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.4222222222222225, 'reward_per_opponent': array([-6.4, -6.4, -6.4, -6.4, -6.4, -6.4, -6.4, -6.6, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 323, num timesteps 23328000, FPS 770
 Last 1800 training episodes: mean/median reward -3.3558/-3.3600, min/max reward -3.4250/-3.2750
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.311111111111111, 'reward_per_opponent': array([-6.3, -6.4, -6.5, -6.3, -6.2, -6.4, -6.2, -6.2, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 324, num timesteps 23400000, FPS 761
 Last 1800 training episodes: mean/median reward -3.3592/-3.3775, min/max reward -3.4350/-3.2800
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 325, num timesteps 23472000, FPS 812
 Last 1800 training episodes: mean/median reward -3.3428/-3.3450, min/max reward -3.4200/-3.2800
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.266666666666666, 'reward_per_opponent': array([-6.4, -6.3, -6.4, -6.3, -6.2, -6.3, -6. , -6.2, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 326, num timesteps 23544000, FPS 768
 Last 1800 training episodes: mean/median reward -3.3467/-3.3450, min/max reward -3.4100/-3.2950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.2666666666666675, 'reward_per_opponent': array([-6.3, -6.1, -6.3, -6.2, -6.3, -6.2, -6.4, -6.4, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 327, num timesteps 23616000, FPS 765
 Last 1800 training episodes: mean/median reward -3.3681/-3.3675, min/max reward -3.4800/-3.2700
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 328, num timesteps 23688000, FPS 800
 Last 1800 training episodes: mean/median reward -3.3547/-3.3575, min/max reward -3.4350/-3.2800
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.300000000000001, 'reward_per_opponent': array([-6.4, -6.2, -6.2, -6.3, -6.3, -6.5, -6.5, -6.2, -6.1]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 329, num timesteps 23760000, FPS 753
 Last 1800 training episodes: mean/median reward -3.3561/-3.3525, min/max reward -3.4450/-3.3150
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.222222222222222, 'reward_per_opponent': array([-6.2, -6.2, -6.4, -6.1, -6.2, -6.2, -6.3, -6.3, -6.1]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 330, num timesteps 23832000, FPS 759
 Last 1800 training episodes: mean/median reward -3.3642/-3.3650, min/max reward -3.4450/-3.2950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.222222222222222, 'reward_per_opponent': array([-6.4, -6.1, -6.4, -6.1, -6.1, -6.4, -6.2, -6.3, -6. ]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 331, num timesteps 23904000, FPS 747
 Last 1800 training episodes: mean/median reward -3.3511/-3.3550, min/max reward -3.4150/-3.2900
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 332, num timesteps 23976000, FPS 799
 Last 1800 training episodes: mean/median reward -3.3486/-3.3450, min/max reward -3.4600/-3.2500
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.222222222222223, 'reward_per_opponent': array([-6.3, -6.3, -6.2, -6.3, -6.2, -6.3, -6.2, -6.1, -6.1]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 333, num timesteps 24048000, FPS 772
 Last 1800 training episodes: mean/median reward -3.3606/-3.3600, min/max reward -3.4850/-3.2700
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.233333333333333, 'reward_per_opponent': array([-6.2, -6.3, -6.3, -6.5, -6.2, -6.2, -6.2, -6.2, -6. ]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 334, num timesteps 24120000, FPS 763
 Last 1800 training episodes: mean/median reward -3.3572/-3.3650, min/max reward -3.4650/-3.2450
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 335, num timesteps 24192000, FPS 810
 Last 1800 training episodes: mean/median reward -3.3539/-3.3600, min/max reward -3.4000/-3.2800
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.322222222222222, 'reward_per_opponent': array([-6.5, -6.4, -6.3, -6.3, -6.2, -6.2, -6.3, -6.3, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 336, num timesteps 24264000, FPS 773
 Last 1800 training episodes: mean/median reward -3.3692/-3.3625, min/max reward -3.4550/-3.3050
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.355555555555556, 'reward_per_opponent': array([-6.4, -6.5, -6.4, -6.3, -6.5, -6.3, -6.2, -6.4, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 337, num timesteps 24336000, FPS 761
 Last 1800 training episodes: mean/median reward -3.3489/-3.3400, min/max reward -3.4250/-3.2750
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.366666666666666, 'reward_per_opponent': array([-6.5, -6.3, -6.4, -6.3, -6.2, -6.5, -6.4, -6.4, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 338, num timesteps 24408000, FPS 763
 Last 1800 training episodes: mean/median reward -3.3500/-3.3500, min/max reward -3.4200/-3.2950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 339, num timesteps 24480000, FPS 798
 Last 1800 training episodes: mean/median reward -3.3628/-3.3450, min/max reward -3.4750/-3.3000
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.322222222222222, 'reward_per_opponent': array([-6.4, -6.4, -6.5, -6.2, -6.2, -6.3, -6.2, -6.4, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 340, num timesteps 24552000, FPS 768
 Last 1800 training episodes: mean/median reward -3.3658/-3.3675, min/max reward -3.4400/-3.3000
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.322222222222222, 'reward_per_opponent': array([-6.2, -6.4, -6.4, -6.5, -6.1, -6.5, -6.3, -6.2, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 341, num timesteps 24624000, FPS 767
 Last 1800 training episodes: mean/median reward -3.3800/-3.3850, min/max reward -3.5000/-3.3050
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 342, num timesteps 24696000, FPS 792
 Last 1800 training episodes: mean/median reward -3.3583/-3.3550, min/max reward -3.4500/-3.2950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.288888888888888, 'reward_per_opponent': array([-6.4, -6.4, -6.3, -6.3, -6.1, -6.3, -6.2, -6.3, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 343, num timesteps 24768000, FPS 752
 Last 1800 training episodes: mean/median reward -3.3508/-3.3475, min/max reward -3.4300/-3.2550
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.277777777777778, 'reward_per_opponent': array([-6.3, -6.3, -6.4, -6.2, -6.2, -6.5, -6.1, -6.3, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 344, num timesteps 24840000, FPS 752
 Last 1800 training episodes: mean/median reward -3.4078/-3.4050, min/max reward -3.5450/-3.3050
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.2444444444444445, 'reward_per_opponent': array([-6.4, -6.3, -6.3, -6.2, -6.2, -6.2, -6.2, -6.1, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 345, num timesteps 24912000, FPS 763
 Last 1800 training episodes: mean/median reward -3.3917/-3.3775, min/max reward -3.4750/-3.3200
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 346, num timesteps 24984000, FPS 798
 Last 1800 training episodes: mean/median reward -3.3750/-3.3725, min/max reward -3.4350/-3.3150
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.311111111111112, 'reward_per_opponent': array([-6.2, -6.3, -6.4, -6.3, -6.4, -6.4, -6. , -6.4, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 347, num timesteps 25056000, FPS 758
 Last 1800 training episodes: mean/median reward -3.3758/-3.3725, min/max reward -3.5100/-3.2900
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Model saved.
 Evaluation using 45 episodes: {'reward': -6.300000000000001, 'reward_per_opponent': array([-6.3, -6.2, -6.3, -6.3, -6.3, -6.3, -6.2, -6.4, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 348, num timesteps 25128000, FPS 756
 Last 1800 training episodes: mean/median reward -3.3517/-3.3500, min/max reward -3.4250/-3.2950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.366666666666666, 'reward_per_opponent': array([-6.5, -6.3, -6.4, -6.4, -6.3, -6.3, -6.4, -6.3, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 349, num timesteps 25200000, FPS 765
 Last 1800 training episodes: mean/median reward -3.3344/-3.3250, min/max reward -3.4150/-3.2750
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 350, num timesteps 25272000, FPS 798
 Last 1800 training episodes: mean/median reward -3.3556/-3.3425, min/max reward -3.4600/-3.2850
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.3, 'reward_per_opponent': array([-6.3, -6.3, -6.4, -6.4, -6.3, -6.3, -6.2, -6.2, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 351, num timesteps 25344000, FPS 751
 Last 1800 training episodes: mean/median reward -3.3561/-3.3575, min/max reward -3.4600/-3.2650
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.311111111111111, 'reward_per_opponent': array([-6.3, -6.2, -6.3, -6.3, -6.4, -6.4, -6.4, -6.2, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 352, num timesteps 25416000, FPS 765
 Last 1800 training episodes: mean/median reward -3.3514/-3.3575, min/max reward -3.4350/-3.2950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 353, num timesteps 25488000, FPS 806
 Last 1800 training episodes: mean/median reward -3.3761/-3.3825, min/max reward -3.4350/-3.2950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.322222222222223, 'reward_per_opponent': array([-6.5, -6.4, -6.4, -6.3, -6.2, -6.5, -6.1, -6.3, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 354, num timesteps 25560000, FPS 763
 Last 1800 training episodes: mean/median reward -3.3739/-3.3725, min/max reward -3.4600/-3.2850
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.3, 'reward_per_opponent': array([-6.1, -6.4, -6.4, -6.3, -6.2, -6.3, -6.4, -6.2, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 355, num timesteps 25632000, FPS 769
 Last 1800 training episodes: mean/median reward -3.3850/-3.3950, min/max reward -3.4900/-3.2800
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.344444444444444, 'reward_per_opponent': array([-6.4, -6.4, -6.3, -6.4, -6.3, -6.4, -6.2, -6.4, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 356, num timesteps 25704000, FPS 762
 Last 1800 training episodes: mean/median reward -3.3750/-3.3800, min/max reward -3.4550/-3.2550
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 357, num timesteps 25776000, FPS 812
 Last 1800 training episodes: mean/median reward -3.3747/-3.3850, min/max reward -3.4300/-3.2900
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.355555555555555, 'reward_per_opponent': array([-6.4, -6.5, -6.3, -6.3, -6.3, -6.3, -6.5, -6.3, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 358, num timesteps 25848000, FPS 761
 Last 1800 training episodes: mean/median reward -3.3628/-3.3525, min/max reward -3.4800/-3.2900
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.322222222222222, 'reward_per_opponent': array([-6.5, -6.3, -6.2, -6.2, -6.3, -6.5, -6.3, -6.3, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 359, num timesteps 25920000, FPS 755
 Last 1800 training episodes: mean/median reward -3.3636/-3.3700, min/max reward -3.4450/-3.2850
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 360, num timesteps 25992000, FPS 809
 Last 1800 training episodes: mean/median reward -3.3744/-3.3750, min/max reward -3.4600/-3.2850
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.322222222222222, 'reward_per_opponent': array([-6.3, -6.2, -6.4, -6.4, -6.3, -6.2, -6.3, -6.4, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 361, num timesteps 26064000, FPS 763
 Last 1800 training episodes: mean/median reward -3.3653/-3.3525, min/max reward -3.4950/-3.2850
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.422222222222222, 'reward_per_opponent': array([-6.5, -6.4, -6.4, -6.4, -6.5, -6.6, -6.4, -6.3, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 362, num timesteps 26136000, FPS 769
 Last 1800 training episodes: mean/median reward -3.3725/-3.3600, min/max reward -3.4750/-3.3250
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.300000000000001, 'reward_per_opponent': array([-6.3, -6.4, -6.3, -6.4, -6.2, -6.2, -6.4, -6.3, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 363, num timesteps 26208000, FPS 750
 Last 1800 training episodes: mean/median reward -3.3603/-3.3675, min/max reward -3.4150/-3.2500
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 364, num timesteps 26280000, FPS 795
 Last 1800 training episodes: mean/median reward -3.3711/-3.3725, min/max reward -3.4350/-3.3000
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.288888888888889, 'reward_per_opponent': array([-6.4, -6.3, -6.2, -6.3, -6.4, -6.2, -6.3, -6.1, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 365, num timesteps 26352000, FPS 761
 Last 1800 training episodes: mean/median reward -3.3867/-3.3950, min/max reward -3.5000/-3.3100
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.322222222222222, 'reward_per_opponent': array([-6.4, -6.3, -6.2, -6.4, -6.3, -6.2, -6.5, -6.3, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 366, num timesteps 26424000, FPS 749
 Last 1800 training episodes: mean/median reward -3.3911/-3.3900, min/max reward -3.4600/-3.2850
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 367, num timesteps 26496000, FPS 774
 Last 1800 training episodes: mean/median reward -3.3872/-3.4025, min/max reward -3.4500/-3.2750
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.388888888888889, 'reward_per_opponent': array([-6.5, -6.5, -6.4, -6.2, -6.3, -6.4, -6.3, -6.5, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 368, num timesteps 26568000, FPS 745
 Last 1800 training episodes: mean/median reward -3.3808/-3.3800, min/max reward -3.4600/-3.3000
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.422222222222222, 'reward_per_opponent': array([-6.4, -6.4, -6.3, -6.4, -6.4, -6.5, -6.5, -6.5, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 369, num timesteps 26640000, FPS 751
 Last 1800 training episodes: mean/median reward -3.3767/-3.3800, min/max reward -3.4700/-3.2950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.288888888888889, 'reward_per_opponent': array([-6.3, -6.3, -6.3, -6.5, -6.2, -6.3, -6.1, -6.2, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 370, num timesteps 26712000, FPS 749
 Last 1800 training episodes: mean/median reward -3.3850/-3.3775, min/max reward -3.4700/-3.2700
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 371, num timesteps 26784000, FPS 788
 Last 1800 training episodes: mean/median reward -3.3664/-3.3700, min/max reward -3.4050/-3.2800
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.355555555555555, 'reward_per_opponent': array([-6.4, -6.3, -6.4, -6.4, -6.3, -6.3, -6.4, -6.3, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 372, num timesteps 26856000, FPS 755
 Last 1800 training episodes: mean/median reward -3.3750/-3.3775, min/max reward -3.4450/-3.2950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.244444444444444, 'reward_per_opponent': array([-6. , -6.2, -6.1, -6.3, -6.3, -6.4, -6.4, -6.1, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 373, num timesteps 26928000, FPS 757
 Last 1800 training episodes: mean/median reward -3.3897/-3.3750, min/max reward -3.4850/-3.2950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.288888888888889, 'reward_per_opponent': array([-6.3, -6. , -6.3, -6.4, -6.2, -6.3, -6.4, -6.3, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 374, num timesteps 27000000, FPS 760
 Last 1800 training episodes: mean/median reward -3.3631/-3.3650, min/max reward -3.4550/-3.2850
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 375, num timesteps 27072000, FPS 799
 Last 1800 training episodes: mean/median reward -3.3617/-3.3500, min/max reward -3.4800/-3.2800
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.188888888888889, 'reward_per_opponent': array([-6.2, -6.3, -6.2, -6. , -6.5, -6.2, -6.1, -6.2, -6. ]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 376, num timesteps 27144000, FPS 759
 Last 1800 training episodes: mean/median reward -3.3950/-3.3900, min/max reward -3.4750/-3.3300
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.144444444444445, 'reward_per_opponent': array([-6.1, -6.2, -6.2, -6.2, -6. , -6.1, -6.4, -6.2, -5.9]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 377, num timesteps 27216000, FPS 759
 Last 1800 training episodes: mean/median reward -3.3767/-3.3725, min/max reward -3.4550/-3.2900
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 378, num timesteps 27288000, FPS 799
 Last 1800 training episodes: mean/median reward -3.3664/-3.3625, min/max reward -3.4800/-3.3000
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.0, 'reward_per_opponent': array([-6. , -6.1, -6. , -6. , -5.9, -6. , -6.1, -5.9, -6. ]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 379, num timesteps 27360000, FPS 757
 Last 1800 training episodes: mean/median reward -3.3419/-3.3425, min/max reward -3.4100/-3.2700
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.0, 'reward_per_opponent': array([-6. , -5.9, -6.1, -6.1, -6. , -6. , -5.9, -6. , -6. ]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 380, num timesteps 27432000, FPS 752
 Last 1800 training episodes: mean/median reward -3.3419/-3.3425, min/max reward -3.4100/-3.2750
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.011111111111111, 'reward_per_opponent': array([-6.1, -6.2, -6. , -6. , -6. , -6. , -5.9, -5.9, -6. ]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 381, num timesteps 27504000, FPS 749
 Last 1800 training episodes: mean/median reward -3.3381/-3.3375, min/max reward -3.4300/-3.2400
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 382, num timesteps 27576000, FPS 785
 Last 1800 training episodes: mean/median reward -3.3317/-3.3225, min/max reward -3.4100/-3.2700
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.044444444444444, 'reward_per_opponent': array([-6.1, -6.1, -6.1, -6. , -5.9, -6.1, -6. , -5.9, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 383, num timesteps 27648000, FPS 730
 Last 1800 training episodes: mean/median reward -3.3344/-3.3400, min/max reward -3.4400/-3.2550
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -5.977777777777778, 'reward_per_opponent': array([-5.9, -6.1, -6. , -6.1, -5.9, -5.9, -6. , -6. , -5.9]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 384, num timesteps 27720000, FPS 747
 Last 1800 training episodes: mean/median reward -3.3297/-3.3300, min/max reward -3.4100/-3.2600
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 385, num timesteps 27792000, FPS 796
 Last 1800 training episodes: mean/median reward -3.3358/-3.3350, min/max reward -3.4250/-3.2750
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.055555555555555, 'reward_per_opponent': array([-6. , -6.2, -6. , -5.9, -6.2, -6.1, -5.9, -6.2, -6. ]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 386, num timesteps 27864000, FPS 758
 Last 1800 training episodes: mean/median reward -3.3439/-3.3250, min/max reward -3.4100/-3.2900
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.133333333333334, 'reward_per_opponent': array([-6.1, -6. , -6.4, -6. , -6.1, -6. , -6.3, -6.1, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 387, num timesteps 27936000, FPS 756
 Last 1800 training episodes: mean/median reward -3.3489/-3.3425, min/max reward -3.4450/-3.2950
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.066666666666666, 'reward_per_opponent': array([-6. , -6.2, -6.2, -6.1, -6.2, -6. , -6. , -6.1, -5.8]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 388, num timesteps 28008000, FPS 761
 Last 1800 training episodes: mean/median reward -3.3375/-3.3325, min/max reward -3.4300/-3.2400
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 389, num timesteps 28080000, FPS 802
 Last 1800 training episodes: mean/median reward -3.3558/-3.3675, min/max reward -3.4100/-3.2700
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.144444444444444, 'reward_per_opponent': array([-6.1, -6.1, -6. , -6.2, -6.1, -6. , -6.4, -6.3, -6.1]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 390, num timesteps 28152000, FPS 759
 Last 1800 training episodes: mean/median reward -3.3339/-3.3150, min/max reward -3.4200/-3.2550
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.166666666666668, 'reward_per_opponent': array([-6.2, -6.3, -5.9, -6.2, -6.2, -6.2, -6.1, -6.2, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 391, num timesteps 28224000, FPS 764
 Last 1800 training episodes: mean/median reward -3.3236/-3.3125, min/max reward -3.4200/-3.2750
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 392, num timesteps 28296000, FPS 791
 Last 1800 training episodes: mean/median reward -3.3347/-3.3350, min/max reward -3.3950/-3.2600
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.288888888888889, 'reward_per_opponent': array([-6.2, -6.4, -6.5, -6.2, -6.1, -6.2, -6.3, -6.3, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 393, num timesteps 28368000, FPS 769
 Last 1800 training episodes: mean/median reward -3.3286/-3.3300, min/max reward -3.4200/-3.2650
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.122222222222224, 'reward_per_opponent': array([-6.1, -6.1, -6.2, -6.2, -6. , -6.2, -6.2, -5.9, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 394, num timesteps 28440000, FPS 762
 Last 1800 training episodes: mean/median reward -3.3228/-3.3175, min/max reward -3.4200/-3.2500
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.255555555555556, 'reward_per_opponent': array([-6.4, -6.1, -6.1, -6.4, -6.4, -6.1, -6.5, -6.1, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 395, num timesteps 28512000, FPS 754
 Last 1800 training episodes: mean/median reward -3.3336/-3.3400, min/max reward -3.4100/-3.2400
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 396, num timesteps 28584000, FPS 798
 Last 1800 training episodes: mean/median reward -3.3383/-3.3350, min/max reward -3.4100/-3.2700
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.2444444444444445, 'reward_per_opponent': array([-6.4, -6.3, -6.2, -6.4, -6.2, -6.1, -6.2, -6.3, -6.1]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 397, num timesteps 28656000, FPS 764
 Last 1800 training episodes: mean/median reward -3.3358/-3.3325, min/max reward -3.3950/-3.2800
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.111111111111111, 'reward_per_opponent': array([-6.1, -5.9, -6. , -5.9, -6.1, -6.3, -6.2, -6.2, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 398, num timesteps 28728000, FPS 760
 Last 1800 training episodes: mean/median reward -3.3422/-3.3325, min/max reward -3.4300/-3.2700
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.222222222222221, 'reward_per_opponent': array([-6. , -6.4, -6.2, -6.3, -6.1, -6.4, -6.1, -6.1, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 399, num timesteps 28800000, FPS 765
 Last 1800 training episodes: mean/median reward -3.3253/-3.3100, min/max reward -3.4200/-3.2600
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 400, num timesteps 28872000, FPS 800
 Last 1800 training episodes: mean/median reward -3.3158/-3.3100, min/max reward -3.3850/-3.2600
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.233333333333333, 'reward_per_opponent': array([-6.1, -6.2, -6.3, -6.1, -6.2, -6.3, -6.2, -6.3, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 401, num timesteps 28944000, FPS 748
 Last 1800 training episodes: mean/median reward -3.3317/-3.3375, min/max reward -3.4300/-3.2350
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.355555555555556, 'reward_per_opponent': array([-6.5, -6.2, -6.3, -6.2, -6.2, -6.4, -6.4, -6.5, -6.5]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 402, num timesteps 29016000, FPS 763
 Last 1800 training episodes: mean/median reward -3.3250/-3.3225, min/max reward -3.4300/-3.2650
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 403, num timesteps 29088000, FPS 795
 Last 1800 training episodes: mean/median reward -3.3172/-3.3075, min/max reward -3.4450/-3.2300
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.2555555555555555, 'reward_per_opponent': array([-6.3, -6.5, -6.3, -6.1, -6.4, -6.1, -6.2, -6.2, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 404, num timesteps 29160000, FPS 758
 Last 1800 training episodes: mean/median reward -3.3111/-3.3175, min/max reward -3.3950/-3.2000
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.311111111111112, 'reward_per_opponent': array([-6.2, -6.3, -6.3, -6.5, -6.4, -6.2, -6.3, -6.2, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 405, num timesteps 29232000, FPS 760
 Last 1800 training episodes: mean/median reward -3.3042/-3.3000, min/max reward -3.3800/-3.2600
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.322222222222223, 'reward_per_opponent': array([-6.5, -6.4, -6.4, -6.3, -6.1, -6.5, -6.2, -6.3, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 406, num timesteps 29304000, FPS 768
 Last 1800 training episodes: mean/median reward -3.2997/-3.3000, min/max reward -3.3750/-3.2450
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 407, num timesteps 29376000, FPS 805
 Last 1800 training episodes: mean/median reward -3.2958/-3.2900, min/max reward -3.3800/-3.2450
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.288888888888889, 'reward_per_opponent': array([-6.4, -6.5, -6.4, -6.3, -6.2, -6.2, -6.3, -6.1, -6.2]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 408, num timesteps 29448000, FPS 770
 Last 1800 training episodes: mean/median reward -3.2936/-3.3000, min/max reward -3.3400/-3.2200
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.166666666666667, 'reward_per_opponent': array([-6.2, -6.3, -6.1, -6. , -6.2, -6.3, -6. , -6.1, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 409, num timesteps 29520000, FPS 761
 Last 1800 training episodes: mean/median reward -3.2942/-3.2925, min/max reward -3.3700/-3.2400
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 410, num timesteps 29592000, FPS 811
 Last 1800 training episodes: mean/median reward -3.3056/-3.3025, min/max reward -3.3950/-3.2400
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.088888888888889, 'reward_per_opponent': array([-6.2, -6.2, -5.9, -6.3, -6.1, -6.1, -6. , -6.1, -5.9]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 411, num timesteps 29664000, FPS 769
 Last 1800 training episodes: mean/median reward -3.2875/-3.2900, min/max reward -3.3900/-3.2200
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.244444444444444, 'reward_per_opponent': array([-6.4, -6.1, -6.3, -6.3, -6.3, -6.1, -6.2, -6.1, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 412, num timesteps 29736000, FPS 772
 Last 1800 training episodes: mean/median reward -3.2772/-3.2775, min/max reward -3.3650/-3.1800
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.3, 'reward_per_opponent': array([-5.9, -6.1, -6.3, -6.4, -6.2, -6.4, -6.5, -6.5, -6.4]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 413, num timesteps 29808000, FPS 775
 Last 1800 training episodes: mean/median reward -3.2919/-3.2875, min/max reward -3.3500/-3.2550
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Updates 414, num timesteps 29880000, FPS 809
 Last 1800 training episodes: mean/median reward -3.2917/-3.2900, min/max reward -3.3950/-3.2350
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
 Evaluation using 45 episodes: {'reward': -6.188888888888888, 'reward_per_opponent': array([-6.2, -6.1, -6.1, -6.1, -6.2, -6.2, -6.2, -6.3, -6.3]), 'success_rate': 0.0, 'success_rate_per_opponent': array([0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'visits_per_interaction': 0.0}
All success rates, by opponent policy: (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)
Updates 415, num timesteps 29952000, FPS 755
 Last 1800 training episodes: mean/median reward -3.2842/-3.2875, min/max reward -3.3300/-3.2250
Mean/median success rate: 0.00/0.00, min/max success rate: 0.00/0.00
Mean visits per interaction: 0.0
Model saved.