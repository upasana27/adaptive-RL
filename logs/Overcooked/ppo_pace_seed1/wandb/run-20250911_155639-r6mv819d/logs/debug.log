2025-09-11 15:56:39,010 INFO    MainThread:578947 [wandb_setup.py:_flush():76] Configure stats pid to 578947
2025-09-11 15:56:39,010 INFO    MainThread:578947 [wandb_setup.py:_flush():76] Loading settings from /home/asurite.ad.asu.edu/ubiswas2/.config/wandb/settings
2025-09-11 15:56:39,010 INFO    MainThread:578947 [wandb_setup.py:_flush():76] Loading settings from /home/asurite.ad.asu.edu/ubiswas2/adaptive-RL/wandb/settings
2025-09-11 15:56:39,010 INFO    MainThread:578947 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2025-09-11 15:56:39,010 INFO    MainThread:578947 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2025-09-11 15:56:39,010 INFO    MainThread:578947 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'train_.py', 'program': 'train_.py'}
2025-09-11 15:56:39,011 INFO    MainThread:578947 [wandb_init.py:_log_setup():506] Logging user logs to ./logs/Overcooked/ppo_pace_seed1/wandb/run-20250911_155639-r6mv819d/logs/debug.log
2025-09-11 15:56:39,011 INFO    MainThread:578947 [wandb_init.py:_log_setup():507] Logging internal logs to ./logs/Overcooked/ppo_pace_seed1/wandb/run-20250911_155639-r6mv819d/logs/debug-internal.log
2025-09-11 15:56:39,011 INFO    MainThread:578947 [wandb_init.py:init():546] calling init triggers
2025-09-11 15:56:39,014 INFO    MainThread:578947 [wandb_init.py:init():552] wandb.init called with sweep_config: {}
config: {'algo': 'ppo', 'gail': False, 'gail_experts_dir': './gail_experts', 'gail_batch_size': 128, 'gail_epoch': 5, 'lr': 0.001, 'eps': 1e-08, 'alpha': 0.99, 'gamma': 0.99, 'use_gae': True, 'gae_lambda': 0.95, 'entropy_coef': 0.03, 'value_loss_coef': 0.5, 'max_grad_norm': 15.0, 'seed': 1, 'pool_seed': 1, 'cuda_deterministic': False, 'num_processes': 72, 'num_steps': 1000, 'num_epochs': 4, 'num_mini_batch': 18, 'mini_batch_size': None, 'num_updates': None, 'clip_param': 0.2, 'log_interval': 10000, 'save_interval': 5000000, 'eval_interval': 100000, 'eval_episodes': 5, 'num_env_steps': 30000000, 'env_name': 'Overcooked', 'no_cuda': False, 'use_proper_time_limits': True, 'recurrent_policy': False, 'rnn_hidden_dim': 0, 'rnn_chunk_length': None, 'share_actor_critic': False, 'use_linear_lr_decay': False, 'use_linear_ent_coef_decay': None, 'disable_advantage_norm': False, 'disable_clipped_value_loss': False, 'act_func': 'relu', 'hidden_channels': None, 'kernel_sizes': None, 'strides': None, 'paddings': None, 'hidden_dims': [128, 128], 'pre_hidden_dims': [128, 128], 'encoder_base': 'mlp', 'agg_func': 'mean', 'act_after_agg': False, 'post_hidden_dims': [128], 'tf_n_layers': None, 'tf_n_heads': None, 'tf_hidden_dim': None, 'tf_ff_dim': None, 'tf_dropout': 0.0, 'tf_pos_emb': 'one_hot', 'tf_chunk_length': None, 'expl_eps': None, 'expl_decay_steps': None, 'expl_eps_final': None, 'buffer_size': None, 'dueling': False, 'target_update_period': None, 'fast_encoder': False, 'identity_encoder': False, 'emb_encoder': False, 'tabular_actor': False, 'tabular_critic': False, 'equal_sampling': False, 'joint_training': False, 'latent_training': True, 'use_latent_critic': True, 'alt_training': None, 'collect_all': False, 'recon_obj': False, 'value_obj': False, 'value_norm': 1, 'e2e_obj': True, 'soft_imitation_init_prob': None, 'soft_imitation_prob_dist': 'const', 'soft_imitation_decay_steps': None, 'soft_imitation_init_ppo_clip': None, 'soft_imitation_ratio_clip': None, 'pcgrad': False, 'latent_dim': 128, 'kl_coef': 0.0, 'kl_cycle': None, 'discrete_latent': False, 'quantize_latent': 0, 'deterministic_latent': True, 'vqvae_beta_coef': 0, 'history_use_episodes': True, 'opponent_switch_period_min': None, 'opponent_switch_period_max': None, 'history_middle_sampling': True, 'history_full_size': 5, 'history_refresh_interval': 1, 'history_size': 5, 'sample_size': None, 'clear_history_on_full': True, 'separate_history': True, 'has_rew_done': False, 'has_meta_time_step': False, 'all_has_rew_done': False, 'all_has_all_time_steps': False, 'auxiliary_policy_cls_coef': 1.0, 'auxiliary_value_pred_coef': None, 'contrastive_n_layers': None, 'contrastive_tau': None, 'self_obs_mode': True, 'self_action_mode': False, 'last_episode_only': False, 'pop_oldest_episode': False, 'auxiliary_transition_pred_coef': None, 'step_mode': False, 'include_current_episode': True, 'encoder_epochs': None, 'encoder_updates': None, 'encoder_mini_batch_size': None, 'encoder_max_samples_per_period': None, 'encoder_update_interval': None, 'merge_encoder_computation': True, 'policy_cls_reward_coef': 0.2, 'policy_cls_reward_type': 'accuracy', 'policy_cls_reward_mode': 'max_full', 'policy_cls_reward_decay_steps': 25000000, 'policy_cls_warmup_steps': 1000000, 'ent_coef_decay_steps': 0, 'contrastive_coef': 0.0, 'pretrained_policy_dir': None, 'multi_agent': 1, 'separate_model': False, 'train_pool_size': 18, 'eval_pool_size': 9, 'opponent_id': None, 'exp_name': 'pace', 'wandb_user_name': 'ubiswas', 'wandb_project_name': None, 'wandb_comment': '', 'save_data': False, 'load_data_dir': None, 'save_partial_ckpt': None, 'use_dummy_vec_env': False, 'use_meta_episode': True, 'pretrained_encoder_dir': None, 'all_has_last_action': False, 'collect_peer_traj': False, 'auxiliary_peer_obs_pred_coef': None, 'auxiliary_peer_act_pred_coef': None, 'collect_next_obs': False, 'env_config': './environment/overcooked/config/forced_coord_1_to_1_full.yaml', 'horizon': None, 'player_id': 0, 'p': 1.0, 'desire_id': None, 'good_pool_only': False, 'rule_based_opponents': 18, 'recipe_type': 'cross', 'visit_reward_type': 'episode', 'visit_reward_coef': 0.0, 'allow_all_opponents': False, 'scenario': None, 'num_agents': 2, 'num_good_agents': None, 'obs_radius': None, 'init_radius': 1.0, 'shaped_reward': False, 'collide_reward': False, 'collide_reward_once': False, 'watch_tower': False, 'shuffle_agents': False, 'separate_patterns': False, 'cuda': True, 'use_advantage_norm': True, 'use_clipped_value_loss': True, 'log_dir': './logs/Overcooked/ppo_pace_seed1', 'save_dir': './logs/Overcooked/ppo_pace_seed1', 'policy_id_max': tensor([18]), 'policy_id_all': tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17]]), 'num_trained_policies': 18}
2025-09-11 15:56:39,015 INFO    MainThread:578947 [wandb_init.py:init():602] starting backend
2025-09-11 15:56:39,015 INFO    MainThread:578947 [wandb_init.py:init():606] setting up manager
2025-09-11 15:56:39,023 INFO    MainThread:578947 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-09-11 15:56:39,030 INFO    MainThread:578947 [wandb_init.py:init():613] backend started and connected
2025-09-11 15:56:39,071 INFO    MainThread:578947 [wandb_init.py:init():701] updated telemetry
2025-09-11 15:56:39,131 INFO    MainThread:578947 [wandb_init.py:init():741] communicating run to backend with 60.0 second timeout
2025-09-11 15:56:39,855 INFO    MainThread:578947 [wandb_run.py:_on_init():2133] communicating current version
2025-09-11 15:56:39,915 INFO    MainThread:578947 [wandb_run.py:_on_init():2142] got version response upgrade_message: "wandb version 0.21.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"

2025-09-11 15:56:39,915 INFO    MainThread:578947 [wandb_init.py:init():789] starting run threads in backend
2025-09-11 15:56:42,058 INFO    MainThread:578947 [wandb_run.py:_console_start():2114] atexit reg
2025-09-11 15:56:42,059 INFO    MainThread:578947 [wandb_run.py:_redirect():1969] redirect: SettingsConsole.WRAP_RAW
2025-09-11 15:56:42,059 INFO    MainThread:578947 [wandb_run.py:_redirect():2034] Wrapping output streams.
2025-09-11 15:56:42,060 INFO    MainThread:578947 [wandb_run.py:_redirect():2059] Redirects installed.
2025-09-11 15:56:42,061 INFO    MainThread:578947 [wandb_init.py:init():831] run started, returning control to user process
