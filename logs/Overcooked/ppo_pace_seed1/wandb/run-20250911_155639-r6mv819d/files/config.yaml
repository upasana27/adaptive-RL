wandb_version: 1

_wandb:
  desc: null
  value:
    cli_version: 0.14.0
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    python_version: 3.8.20
    start_time: 1757631399.030876
    t:
      1:
      - 1
      - 55
      2:
      - 1
      - 55
      3:
      - 13
      - 16
      - 23
      4: 3.8.20
      5: 0.14.0
      8:
      - 5
act_after_agg:
  desc: null
  value: false
act_func:
  desc: null
  value: relu
agg_func:
  desc: null
  value: mean
algo:
  desc: null
  value: ppo
all_has_all_time_steps:
  desc: null
  value: false
all_has_last_action:
  desc: null
  value: false
all_has_rew_done:
  desc: null
  value: false
allow_all_opponents:
  desc: null
  value: false
alpha:
  desc: null
  value: 0.99
alt_training:
  desc: null
  value: null
auxiliary_peer_act_pred_coef:
  desc: null
  value: null
auxiliary_peer_obs_pred_coef:
  desc: null
  value: null
auxiliary_policy_cls_coef:
  desc: null
  value: 1.0
auxiliary_transition_pred_coef:
  desc: null
  value: null
auxiliary_value_pred_coef:
  desc: null
  value: null
buffer_size:
  desc: null
  value: null
clear_history_on_full:
  desc: null
  value: true
clip_param:
  desc: null
  value: 0.2
collect_all:
  desc: null
  value: false
collect_next_obs:
  desc: null
  value: false
collect_peer_traj:
  desc: null
  value: false
collide_reward:
  desc: null
  value: false
collide_reward_once:
  desc: null
  value: false
contrastive_coef:
  desc: null
  value: 0.0
contrastive_n_layers:
  desc: null
  value: null
contrastive_tau:
  desc: null
  value: null
cuda:
  desc: null
  value: true
cuda_deterministic:
  desc: null
  value: false
desire_id:
  desc: null
  value: null
deterministic_latent:
  desc: null
  value: true
disable_advantage_norm:
  desc: null
  value: false
disable_clipped_value_loss:
  desc: null
  value: false
discrete_latent:
  desc: null
  value: false
dueling:
  desc: null
  value: false
e2e_obj:
  desc: null
  value: true
emb_encoder:
  desc: null
  value: false
encoder_base:
  desc: null
  value: mlp
encoder_epochs:
  desc: null
  value: null
encoder_max_samples_per_period:
  desc: null
  value: null
encoder_mini_batch_size:
  desc: null
  value: null
encoder_update_interval:
  desc: null
  value: null
encoder_updates:
  desc: null
  value: null
ent_coef_decay_steps:
  desc: null
  value: 0
entropy_coef:
  desc: null
  value: 0.03
env_config:
  desc: null
  value: ./environment/overcooked/config/forced_coord_1_to_1_full.yaml
env_name:
  desc: null
  value: Overcooked
eps:
  desc: null
  value: 1.0e-08
equal_sampling:
  desc: null
  value: false
eval_episodes:
  desc: null
  value: 5
eval_interval:
  desc: null
  value: 100000
eval_pool_size:
  desc: null
  value: 9
exp_name:
  desc: null
  value: pace
expl_decay_steps:
  desc: null
  value: null
expl_eps:
  desc: null
  value: null
expl_eps_final:
  desc: null
  value: null
fast_encoder:
  desc: null
  value: false
gae_lambda:
  desc: null
  value: 0.95
gail:
  desc: null
  value: false
gail_batch_size:
  desc: null
  value: 128
gail_epoch:
  desc: null
  value: 5
gail_experts_dir:
  desc: null
  value: ./gail_experts
gamma:
  desc: null
  value: 0.99
good_pool_only:
  desc: null
  value: false
has_meta_time_step:
  desc: null
  value: false
has_rew_done:
  desc: null
  value: false
hidden_channels:
  desc: null
  value: null
hidden_dims:
  desc: null
  value:
  - 128
  - 128
history_full_size:
  desc: null
  value: 5
history_middle_sampling:
  desc: null
  value: true
history_refresh_interval:
  desc: null
  value: 1
history_size:
  desc: null
  value: 5
history_use_episodes:
  desc: null
  value: true
horizon:
  desc: null
  value: null
identity_encoder:
  desc: null
  value: false
include_current_episode:
  desc: null
  value: true
init_radius:
  desc: null
  value: 1.0
joint_training:
  desc: null
  value: false
kernel_sizes:
  desc: null
  value: null
kl_coef:
  desc: null
  value: 0.0
kl_cycle:
  desc: null
  value: null
last_episode_only:
  desc: null
  value: false
latent_dim:
  desc: null
  value: 128
latent_training:
  desc: null
  value: true
load_data_dir:
  desc: null
  value: null
log_dir:
  desc: null
  value: ./logs/Overcooked/ppo_pace_seed1
log_interval:
  desc: null
  value: 10000
lr:
  desc: null
  value: 0.001
max_grad_norm:
  desc: null
  value: 15.0
merge_encoder_computation:
  desc: null
  value: true
mini_batch_size:
  desc: null
  value: null
multi_agent:
  desc: null
  value: 1
no_cuda:
  desc: null
  value: false
num_agents:
  desc: null
  value: 2
num_env_steps:
  desc: null
  value: 30000000
num_epochs:
  desc: null
  value: 4
num_good_agents:
  desc: null
  value: null
num_mini_batch:
  desc: null
  value: 18
num_processes:
  desc: null
  value: 72
num_steps:
  desc: null
  value: 1000
num_trained_policies:
  desc: null
  value: 18
num_updates:
  desc: null
  value: null
obs_radius:
  desc: null
  value: null
opponent_id:
  desc: null
  value: null
opponent_switch_period_max:
  desc: null
  value: null
opponent_switch_period_min:
  desc: null
  value: null
p:
  desc: null
  value: 1.0
paddings:
  desc: null
  value: null
pcgrad:
  desc: null
  value: false
player_id:
  desc: null
  value: 0
policy_cls_reward_coef:
  desc: null
  value: 0.2
policy_cls_reward_decay_steps:
  desc: null
  value: 25000000
policy_cls_reward_mode:
  desc: null
  value: max_full
policy_cls_reward_type:
  desc: null
  value: accuracy
policy_cls_warmup_steps:
  desc: null
  value: 1000000
policy_id_all:
  desc: null
  value:
  - - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
    - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    - 16
    - 17
policy_id_max:
  desc: null
  value: '18'
pool_seed:
  desc: null
  value: 1
pop_oldest_episode:
  desc: null
  value: false
post_hidden_dims:
  desc: null
  value:
  - 128
pre_hidden_dims:
  desc: null
  value:
  - 128
  - 128
pretrained_encoder_dir:
  desc: null
  value: null
pretrained_policy_dir:
  desc: null
  value: null
quantize_latent:
  desc: null
  value: 0
recipe_type:
  desc: null
  value: cross
recon_obj:
  desc: null
  value: false
recurrent_policy:
  desc: null
  value: false
rnn_chunk_length:
  desc: null
  value: null
rnn_hidden_dim:
  desc: null
  value: 0
rule_based_opponents:
  desc: null
  value: 18
sample_size:
  desc: null
  value: null
save_data:
  desc: null
  value: false
save_dir:
  desc: null
  value: ./logs/Overcooked/ppo_pace_seed1
save_interval:
  desc: null
  value: 5000000
save_partial_ckpt:
  desc: null
  value: null
scenario:
  desc: null
  value: null
seed:
  desc: null
  value: 1
self_action_mode:
  desc: null
  value: false
self_obs_mode:
  desc: null
  value: true
separate_history:
  desc: null
  value: true
separate_model:
  desc: null
  value: false
separate_patterns:
  desc: null
  value: false
shaped_reward:
  desc: null
  value: false
share_actor_critic:
  desc: null
  value: false
shuffle_agents:
  desc: null
  value: false
soft_imitation_decay_steps:
  desc: null
  value: null
soft_imitation_init_ppo_clip:
  desc: null
  value: null
soft_imitation_init_prob:
  desc: null
  value: null
soft_imitation_prob_dist:
  desc: null
  value: const
soft_imitation_ratio_clip:
  desc: null
  value: null
step_mode:
  desc: null
  value: false
strides:
  desc: null
  value: null
tabular_actor:
  desc: null
  value: false
tabular_critic:
  desc: null
  value: false
target_update_period:
  desc: null
  value: null
tf_chunk_length:
  desc: null
  value: null
tf_dropout:
  desc: null
  value: 0.0
tf_ff_dim:
  desc: null
  value: null
tf_hidden_dim:
  desc: null
  value: null
tf_n_heads:
  desc: null
  value: null
tf_n_layers:
  desc: null
  value: null
tf_pos_emb:
  desc: null
  value: one_hot
train_pool_size:
  desc: null
  value: 18
use_advantage_norm:
  desc: null
  value: true
use_clipped_value_loss:
  desc: null
  value: true
use_dummy_vec_env:
  desc: null
  value: false
use_gae:
  desc: null
  value: true
use_latent_critic:
  desc: null
  value: true
use_linear_ent_coef_decay:
  desc: null
  value: null
use_linear_lr_decay:
  desc: null
  value: false
use_meta_episode:
  desc: null
  value: true
use_proper_time_limits:
  desc: null
  value: true
value_loss_coef:
  desc: null
  value: 0.5
value_norm:
  desc: null
  value: 1
value_obj:
  desc: null
  value: false
visit_reward_coef:
  desc: null
  value: 0.0
visit_reward_type:
  desc: null
  value: episode
vqvae_beta_coef:
  desc: null
  value: 0
wandb_comment:
  desc: null
  value: ''
wandb_project_name:
  desc: null
  value: null
wandb_user_name:
  desc: null
  value: ubiswas
watch_tower:
  desc: null
  value: false
